<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[手把手教你用node撸一个图片压缩工具]]></title>
    <url>%2F2018%2F10%2F27%2FimgMin%2F</url>
    <content type="text"><![CDATA[上篇文章中我们提到了用node撸一个简易的爬虫，本次基于上一篇文章中的项目get_picture给大家分享下我是如何用node撸一个图片压缩工具的。 历史：《手把手教你用node撸一个简易的headless爬虫cli工具》 tinypng依然是先介绍一下工具，本次我们主要用到了 tinypng 这个工具。tinypng是一个主流的图片压缩工具，他可以实现高保真的压缩我们的图片，一般我们可以进入他的官网https://tinypng.com/压缩图片，手动点击上传，但是每次只能压缩20张，这对于追求方便的我们来说肯定是不能满足的。我们需要一次性将所有图片都压缩！ 这怎么办呢？tinypng官网十分的人性化，提供了各种服务端直接调用的接口，我们点开他的文档看一看，找到node.js，通过npm i --save tinify安装在我们的项目中，其次可以看到他提供了各种各样的功能，包括压缩图片、resize图片、上传cdn等。我们主要用到了他的压缩图片、验证key、查看已用数。 目录结构1234567891011121314151617181920|-- Documents |-- .gitignore |-- README.md |-- package.json |-- bin | |-- gp |-- output | |-- .gitkeeper |-- src |-- app.js |-- clean.js |-- imgMin.js |-- index.js |-- config | |-- default.js |-- helper |-- questions.js |-- regMap.js |-- srcToImg.js |-- tinify.js 基于上一个项目，我们新增了两个文件 /src/imgMin.js。即我们的主文件。 /src/helper/tinify.js。主要用于操作tinypng的相关API 主文件在主文件中，我们主要用到了node的fs模块。首先我们会判断输入的key是否有效，其次我们会判断该key剩余可用数是不是小于0，如果没问题的话，我们就开始查找检索路径下的所有文件。 检索路径首先我们会通过fs.stat判断该路径是否是文件夹，如果是，则通过fs.readdir获取当前文件列表，遍历后然后将其传给获取图片方法。注意这边有个坑点，因为我们的操作几乎都是异步操作，所以我一开始也很理所当然的用了forEach来遍历，伪代码如下123files.forEach(async (file) =&gt; &#123; await getImg(file);&#125;); 后来发现，这种写法会导致await并不能如我们预期的阻断来执行，而是变成了一个同步的过程（一开始的预期是一张图片压缩输出完才执行第二张，虽然这样会导致很慢。所以后面还是换成了同步压缩），这是因为forEach可以理解为传入一个function，然后在内部执行循环，在循环中执行function并传回index和item，如果传入的是async函数的话，则其实是并行执行了多个匿名async函数自调，因此await无法按照我们预期的来执行。所以该处我们采用for-of循环，伪代码如下123for(let file of files)&#123; await getImg(file);&#125; 获取图片在获取图片中，我们依然会通过fs.stat来判断，如果当前文件依然是个文件夹，我们则递归调用findImg检索其下的文件，如果是图片，先判断当前累计图片总数有没有超过剩余数的最大值（如果使用异步压缩，则不需要进行这一步，因为每一次图片处理都是等待上一张图片处理完成后再进行处理；如果是同步压缩，则必须要这一步，否则如果压缩过程中超数量了，会导致整批压缩失败），如果没有超过，则通过调用tinify.js中的imgMin方法开始进行压缩。 压缩图片在这一步中，我们先通过fs.readFile读取文件内容sourceData，再通过tinypng的APItinify.fromBuffer(sourceData).toBuffer((err, resultData) =&gt; {})方法获取图片压缩后的数据resuleData，最后通过fs.writeFile对原图片进行覆盖。需要注意一点，async/await中，只有遇到await才会等待执行，并且await后面需要跟一个promise对象，因此，我们把readFile、tinify.fromBuffer(sourceData).toBuffer((err, resultData) =&gt; {})、fs.writeFile用promise进行封装。至此，我们的主程序就大功告成了！怎么样，是不是依然非常简单。最后只要在commander中加入我们的新命令就好了。 /src/imgMin.js代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586const path = require('path');const fs = require('fs');const chalk = require('chalk');const defaultConf = require('./config/default');const &#123; promisify &#125; = require('util');const readdir = promisify(fs.readdir);const stat = promisify(fs.stat);const regMap = require('./helper/regMap');const &#123; validate, leftCount, imgMin &#125; = require('./helper/tinify');class ImgMin &#123; constructor(conf) &#123; this.conf = Object.assign(&#123;&#125;, defaultConf, conf); this.imgs = 0; &#125; async isDir(filePath) &#123; try &#123; const stats = await stat(filePath); if(stats.isDirectory())&#123; return true; &#125; return false; &#125; catch (error) &#123; return false; &#125; &#125; async findImg(filePath) &#123; try &#123; const isDirectory = await this.isDir(filePath); if(!isDirectory)&#123; return; &#125; const files = await readdir(filePath); for(let file of files)&#123; // 这里不能用forEach，只能用for循环 // 加上await，则是一张张异步压缩图片，如果中间出错，则部分成功 // 不加await，则是同步发起压缩图片请求，异步写入，如果中间出错，则全部失败 // 这里为了压缩更快，采用同步写法 // await this.getImg(file); const fullPath = path.join(filePath, file); this.getImg(fullPath); &#125; &#125; catch (error) &#123; console.log(error); &#125; &#125; async getImg(file) &#123; const stats = await stat(file); // 如果是文件夹，则递归调用findImg if(stats.isDirectory())&#123; this.findImg(); &#125;else if(stats.isFile())&#123; if(regMap.isTinyPic.test(file))&#123; this.imgs ++; const left = leftCount(); // 剩余数判断，解决同步时剩余数不足导致的全部图片压缩失败问题 if(this.imgs &gt; left || left &lt; 0)&#123; console.log(chalk.red(`当前key的可用剩余数不足！$&#123;file&#125; 压缩失败！`)); return; &#125; await imgMin(file); &#125;else&#123; console.log(chalk.red(`不支持的文件格式 $&#123;file&#125;`)); &#125; &#125; &#125; async start() &#123; try &#123; const isValidated = await validate(this.conf.key); if(!isValidated)&#123; return; &#125; const filePath = this.conf.imgMinPath; await this.findImg(filePath); &#125; catch (error) &#123; console.log(error); &#125; &#125;&#125;module.exports = ImgMin; /src/helper/tinify.js代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475const fs = require('fs');const tinify = require('tinify');const chalk = require('chalk');const &#123; promisify &#125; = require('util');const readFile = promisify(fs.readFile);function setKey(key) &#123; tinify.key = key;&#125;async function validate(key) &#123; console.log(chalk.green('正在认证tinyPng的key...')); setKey(key); return new Promise(resolve =&gt; &#123; tinify.validate((err) =&gt; &#123; if(err)&#123; console.log(err); return resolve(false); &#125; console.log(chalk.green('认证成功！')); const left = leftCount(); if(left &lt;= 0)&#123; console.log(chalk.red('当前key的剩余可用数已用尽，请更换key重试！')); return resolve(false); &#125; console.log(chalk.green(`当前key剩余可用数为 $&#123;left&#125;`)); resolve(true); &#125;); &#125;);&#125;;function compressionCount() &#123; return tinify.compressionCount;&#125;;function leftCount() &#123; const total = 500; return total - Number(compressionCount());&#125;;function writeFilePromise(file, content, cb) &#123; return new Promise((resolve, reject) =&gt; &#123; fs.writeFile(file, content, (err) =&gt; &#123; if(err)&#123; return reject(err); &#125; cb &amp;&amp; cb(); resolve(); &#125;); &#125;);&#125;;function toBufferPromise(sourceData) &#123; return new Promise((resolve, reject) =&gt; &#123; tinify.fromBuffer(sourceData).toBuffer((err, resultData) =&gt; &#123; if (err) &#123; return reject(err); &#125; resolve(resultData); &#125;) &#125;);&#125;;async function imgMin(img) &#123; try &#123; console.log(chalk.blue(`开始压缩图片 $&#123;img&#125;`)); const sourceData = await readFile(img); const resultData = await toBufferPromise(sourceData); await writeFilePromise(img, resultData, () =&gt; console.log(chalk.green(`图片压缩成功 $&#123;img&#125;`))); &#125; catch (error) &#123; console.log(error); &#125;&#125;;module.exports = &#123; validate, compressionCount, leftCount, imgMin &#125;; 命令行工具在index.js中，我们加入以下代码123456789101112131415161718program .command('imgMin') .alias('p') .option('-k, --key [key]', `Tinypng's key, Required`) .option('-p, --path [path]', `Compress directory. By default, the /images in the current working directory are taken. Please enter an absolute path such as /Users/admin/Documents/xx...`) .description('Compress your images by tinypng.') .action(options =&gt; &#123; let conf = &#123;&#125;; if(!options.key)&#123; console.log(chalk.red(`Please enter your tinypng's key by "gp p -k [key]"`)); return; &#125; options.key &amp;&amp; (conf.key = options.key); options.path &amp;&amp; (conf.imgMinPath = options.path); const imgMin = new ImgMin(conf); imgMin.start(); &#125;); commander具体的用法本章就不再重复了，相信有心的同学通过上章的学习已经掌握基本用法了~ 这样，我们就完成了我们的需求，再将其更新到npm中，我们就可以通过gp p -k [key]来压缩我们的图片。 项目下载npm i get_picture -g 参考链接 该项目的git链接 https://github.com/1eeing/get_picture tinypng官网https://tinypng.com/ commander git链接 https://github.com/tj/commander.js]]></content>
      <categories>
        <category>个人原创</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>cli</tag>
        <tag>commander</tag>
        <tag>tinypng</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手把手教你用node撸一个简易的headless爬虫cli工具]]></title>
    <url>%2F2018%2F10%2F17%2Fget_picture%2F</url>
    <content type="text"><![CDATA[众所周知，node功能很强大，为前端提供了更多的可能。今天，就跟大家分享一下我是如何用node写一个headless爬虫的 用到的工具 puppeteer commander inquirer chalk 下面就给大家讲一下这些工具都有什么作用 puppeteerheadless爬虫主要靠它。它可以模拟用户打开网页的过程，但是并没有打开网页。写过自动化测试的同学应该对这个会比较熟悉，因为用它爬虫的过程跟自动化测试的过程几乎是一样的。 commander基于node的cli命令行工具。利用它，我们可以很方便的写出各种各样的cli命令。 inquirer交互式命令行工具。什么叫做交互式命令行呢？其实就是类似npm init的时候，问一个问题，我们答一个问题，最后根据答案生成package.json的过程。 chalk这个其实就是一个让我们在命令行中输出的文字更加优美的工具。 好了，介绍完了工具以后，让我们正式开始我们的项目。 项目介绍首先，要搞清楚我们想要实现的功能。我们想要实现的功能就是，在命令行中输入我们想要下载的图片，然后node去网上爬取我们想要的图片（这里就先去百度图片爬吧），直接下载到本地。以及输入一个命令，可以清空我们输出目录中的图片。 文件目录123456789101112131415161718|-- Documents |-- .gitignore |-- README.md |-- package.json |-- bin | |-- gp |-- output | |-- .gitkeeper |-- src |-- app.js |-- clean.js |-- index.js |-- config | |-- default.js |-- helper |-- questions.js |-- regMap.js |-- srcToImg.js 以上是项目用到的一个简单的目录结构 output 用以存放下载的图片 bin cli工具会用到的文件 src 代码主要存放于此 index.js 项目入口文件 app.js 主要功能文件 clean.js 用于清空图片操作的文件 config 用于存放一些配置 helper 用于存放一些辅助方法的文件 开始项目首先我们看一下app.js。 我们用一个类包裹核心方法，是为了命令行工具可以更方便的调用我们的方法。 这个类很简单，constructor接收参数，start开启主要流程。start方法是一个async函数，因为puppeteer操作浏览器的过程几乎都是异步的。 接着我们用puppeteer生成page的实例，利用goto方法模拟进入百度图片页面。这时其实就是跟我们真实打开浏览器进入百度图片是一样的，只不过因为我们是headless的，所以我们无法感知打开浏览器的过程。 然后我们需要设置一下浏览器的宽度（想象一下），不能太大，也不能太小。太大会触发百度反爬虫机制，导致我们爬下来的图片是403或者别的错误。太小会导致爬到的图片非常少。 接下去我们聚焦搜索框，输入我们想要搜索的关键字（这个关键字呢就是我们在命令行输入的关键字），然后点击搜索。 等页面加载以后，我们用page.$$eval获取页面上所有class为.main_img的图片（具体规律需要自己去观察），再获取上面的src属性后，将src转为我们本地的图片。 到这里，app.js的任务就完成了。很简单吧。 下面是代码。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455const puppeteer = require('puppeteer');const chalk = require('chalk');const config = require('./config/default');const srcToImg = require('./helper/srcToImg');class App &#123; constructor(conf) &#123; //有传入的参数既用传入的参数，没有既用默认的参数 this.conf = Object.assign(&#123;&#125;, config, conf); &#125; async start () &#123; //用puppeteer生成一个browser的实例 //用browser再生成一个page的实例 const browser = await puppeteer.launch(); const page = await browser.newPage(); //打开搜索引擎，先写死百度 await page.goto(this.conf.searchPath); console.log(chalk.green(`go to $&#123;this.conf.searchPath&#125;`)); //设置窗口大小，过大会引起反爬虫 await page.setViewport(&#123; width: 1920, height: 700 &#125;); //搜索文字输入框聚焦 await page.focus('#kw'); //输入要搜索的关键字 await page.keyboard.sendCharacter(this.conf.keyword); //点击搜索 await page.click('.s_search'); console.log(chalk.green(`get start searching pictures`)); //页面加载后要做的事 page.on('load', async () =&gt; &#123; console.log(chalk.green(`searching pictures done, start fetch...`)); //获取所有指定图片的src const srcs = await page.$$eval('img.main_img', pictures =&gt; &#123; return pictures.map(img =&gt; img.src); &#125;); console.log(chalk.green(`get $&#123;srcs.length&#125; pictures, start download`)); srcs.forEach(async (src) =&gt; &#123; await page.waitFor(200); await srcToImg(src, this.conf.outputPath); &#125;); &#125;); &#125;&#125;;module.exports = App; 接下来我们看一下，如何把图片的src属性转化为我们本地的图片呢？我们看下helper下的srcToImg.js 首先，这个模块主要引入了node的http模块、https模块、path模块和fs模块及一些辅助工具，比如正则、将回调函数转化为promise的promisify和将输出更好看的chalk。 为什么我们要同时引入http和https模块呢？仔细观察百度图片搜索结果中的图片，我们可以发现，既有http的也有https的，所以我们引入两个模块，区分出具体的图片属于哪个就用哪个模块去请求图片。请求了图片以后，我们就用fs模块的createWriteStream方法，将图片存入我们的output目录中。 如果我们仔细观察了百度搜索结果中的图片的src，我们会发现，除了http和https开头的图片，还有base64的图片，所以我们要对base64的图片也做一下处理。 跟普通图片一样的处理，先根据src分割出扩展名，再计算出存储的路径和文件名，最后写入调用fs模块的writeFile方法写入文件（这里就简单的用writeFile了）。 以上，图片就存入本地了。 代码如下。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849const http = require('http');const https = require('https');const path = require('path');const fs = require('fs');const &#123; promisify &#125; = require('util');const chalk = require('chalk');const writeFile = promisify(fs.writeFile);const regMap = require('./regMap');const urlToImg = promisify((url, dir) =&gt; &#123; let mod; if(regMap.isHttp.test(url))&#123; mod = http; &#125;else if(regMap.isHttps.test(url))&#123; mod = https; &#125; //获取图片的扩展名 const ext = path.extname(url); //拼接图片存储的路径和扩展名 const file = path.join(dir, `$&#123;parseInt(Math.random() * 1000000)&#125;$&#123;ext&#125;`); mod.get(url, res =&gt; &#123; //采用stream的形式，比直接写入更快捷 res.pipe(fs.createWriteStream(file)).on('finish', () =&gt; &#123; console.log(file); &#125;); &#125;);&#125;);const base64ToImg = async (base64Str, dir) =&gt; &#123; const matchs = base64Str.match(regMap.isBase64); try &#123; const ext = matchs[1].split('/')[1].replace('jpeg', 'jpg'); const file = path.join(dir, `$&#123;parseInt(Math.random() * 1000000)&#125;.$&#123;ext&#125;`); await writeFile(file, matchs[2], 'base64'); console.log(file); &#125; catch (error) &#123; console.log(chalk.red('无法识别的图片')); &#125;&#125;;module.exports = (src, dir) =&gt; &#123; if(regMap.isPic.test(src))&#123; urlToImg(src, dir); &#125;else&#123; base64ToImg(src, dir); &#125;&#125;; 我们再看一下如何清空output下的图片呢？这里我们还是用到了node的fs模块，首先利用fs.readdir方法读取output文件夹，然后遍历其下的文件，如果是图片，则调用fs.unlink方法删除它。也很简单，对吧。 代码如下1234567891011121314151617181920212223242526272829const fs = require('fs');const regMap = require('./helper/regMap');const config = require('./config/default');const cleanPath = config.outputPath;class Clean &#123; constructor() &#123;&#125; clean() &#123; fs.readdir(cleanPath, (err, files) =&gt; &#123; if(err)&#123; throw err; &#125; files.forEach(file =&gt; &#123; if(regMap.isPic.test(file))&#123; const img = `$&#123;cleanPath&#125;/$&#123;file&#125;`; fs.unlink(img, (e) =&gt; &#123; if(e) &#123; throw e; &#125; &#125;); &#125; &#125;); console.log('clean finished'); &#125;); &#125;&#125;;module.exports = Clean; 最后我们看一下如何写cli工具呢？首先我们需要在bin目录下新建一个脚本文件gp，如下12#! /usr/bin/env nodemodule.exports = require(&apos;../src/index&apos;); 意思是找到/usr/bin/env下的node来启动第二行的代码 其次我们需要在package.json里加入一个bin对象，对象下属性名是我们命令的名字，属性是bin下的脚本文件的路径，如下123"bin": &#123; "gp": "bin/gp"&#125; 接着我们来看下index.js1234567891011121314151617181920212223242526272829303132333435const program = require('commander');const inquirer = require('inquirer');const pkg = require('../package.json');const qs = require('./helper/questions');const App = require('./app');const Clean = require('./clean');program .version(pkg.version, '-v, --version');program .command('search') .alias('s') .description('get search pictures what you want.') .action(async () =&gt; &#123; const answers = await inquirer.prompt(qs.startQuestions); const app = new App(answers); await app.start(); &#125;);program .command('clean') .alias('c') .description('clean all pictures in directory "output".') .action(async () =&gt; &#123; const answers = await inquirer.prompt(qs.confirmClean); const clean = new Clean(); answers.isRemove &amp;&amp; await clean.clean(); &#125;); program.parse(process.argv);if(process.argv.length &lt; 3)&#123; program.help();&#125; 我们引入commander和inquirer，program.command方法是为我们生成命令名的，alias是该命令的缩写，description是该命令的描述，action是该命令要做的事情。 我们首先用command生成了两个命令，search和clean，接着可以看到，我们在action中用了inquirer，inquirer的提问是一个异步的过程，所以我们也一样用了async和await，inquirer接收一个问题数组，里面包含问题的type、name、message和验证方法等，具体的可以参考inquirer的文档。我们这里的问题如下，这里返回了两个数组，一个是用于输入关键字的时候的，一个是用于清空图片时确认的。提问数组中会验证是否有填写关键字，如果没有，则不会继续下一步并提示你该输入关键字，否则就正式开始爬虫流程。删除确认数组就是简单的一个确认，如果确认了，则开始删除图片。最后，用program.parse将命令注入到node的process.argv中，根据命令行有没有输入参数提示help信息。 至此，我们的程序大功告成。接下去我们只要将我们的程序发布到npm里，就可以让其他人下载来使用了~npm的发布我们这里就不再赘述啦，不清楚的同学网上随便搜一下就ok啦。 src/helper/questions.js如下1234567891011121314151617181920212223242526const config = require('../config/default');exports.startQuestions = [ &#123; type: 'input', name: 'keyword', message: 'What pictures do yo want to get ?', validate: function(keyword) &#123; const done = this.async(); if(keyword === '')&#123; done('Please enter the keyword to get pictures'); return; &#125; done(null, true); &#125; &#125;];exports.confirmClean = [ &#123; type: 'confirm', name: 'isRemove', message: `Do you want to remove all pictures in $&#123;config.outputPath&#125; ?`, default: true, &#125;]; 项目下载npm i get_picture -g 参考链接 该项目的git链接 https://github.com/1eeing/get_picture puppeteer git链接 https://github.com/GoogleChrome/puppeteer commander git链接 https://github.com/tj/commander.js inquirer git链接 https://github.com/SBoudrias/Inquirer.js]]></content>
      <categories>
        <category>个人原创</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>cli</tag>
        <tag>commander</tag>
        <tag>inquirer</tag>
        <tag>puppeteer</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底搞懂Nginx]]></title>
    <url>%2F2018%2F09%2F13%2FNginx%2F</url>
    <content type="text"><![CDATA[前言Nginx在工作中用的很多，平时开发也一直用Nginx来代理，但是一直对Nginx是一个模糊的概念。这次打算结合理论和工作中的Nginx配置彻底搞清楚Nginx。 Nginx能做什么 正向代理 反向代理 负载均衡 HTTP服务器 正向代理正向代理，也就是传说中的代理，他的工作原理就像一个跳板，简单的说，我是一个用户，我访问不了某网站，但是我能访问一个代理服务器，这个代理服务器呢，他能访问那个我不能访问的网站，于是我先连上代理服务器，告诉他我需要那个无法访问网站的内容，代理服务器去取回来，然后返回给我。从网站的角度，只在代理服务器来取内容的时候有一次记录，有时候并不知道是用户的请求，也隐藏了用户的资料，这取决于代理告不告诉网站。 专业点说：正向代理是一个位于客户端和原始服务器（origin server）之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并制定目标（原始服务器），然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特殊的设置才能使用正向代理 关键代码如下123456789resolver 114.114.114.114 8.8.8.8;server &#123; resolver_timeout 5s; listen 81; location / &#123; proxy_pass http://$host$request_uri; &#125;&#125; resolver是配置正向代理的DNS服务器，listen是正向代理的端口，配置好了就可以在代理插件上通过服务器ip+端口号进行代理了。 反向代理继续举例。用户访问http://www.test.com/readme，但www.test.com上并不存在readme页面，他是偷偷从另外一台服务器上取回来，然后作为自己的内容返回用户，但用户并不知情。这里提到的www.test.com这个域名对应的服务器就设置了反向代理功能。 结论就是：反向代理和正向代理正好相反，对于客户端而言他就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理的命名空间中的内容发送普通请求，接着反向代理将判断向何处（原始服务器）转交请求，并将获得的内容返回给客户端，就像这些内容原本就是他自己的一样。 关键代码如下12345678server &#123; listen 80; server_name localhost; location / &#123; proxy_pass http://localhost:8080; &#125;&#125; 这样当我们访问localhost:80时，80端口会向8080端口转交请求，并将内容返回给我们客户端，就相当于访问localhost:8080了。 负载均衡负载均衡也是Nginx常用的一个功能，负载均衡的意思就是分摊到多个操作单元上进行执行，例如Web服务器，FTP服务器、企业关键应用服务器和其它关键人物服务器等，从而共同完成工作任务。简单而言，就是当有2台或以上服务器时，根据规则随机的将请求分发到制定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。 Nginx自带3种负载均衡策略，还有2种常用的第三方策略。 RR（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器挂了，则自动剔除。 核心代码123456789101112upstream test &#123; server localhost:8080; server localhost:8081;&#125;server &#123; listen 80; server_name localhost; location / &#123; proxy_pass http://test; &#125;&#125; upstream 部分即为负载均衡的核心代码。这里配置2个端口，而8081端口是访问不到的，但是我们访问 http://localhost 的时候也不会有问题，会默认跳转到 http://localhost:8080 具体是因为Nginx会自动判断服务器的状态，如果服务器挂了，则不会跳转到这台服务器。 权重制定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 核心代码如下1234upstream test &#123; server localhost:8080 weight=9; server localhost:8081 weight=1;&#125; 那么10次一般只有1次会访问到8081，剩下9次会访问到8080。 ip_hash上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分到另一个服务器，当我们的程序不是无状态的时候（采用了session保存数据），这时候就有一个很大的问题了，比如把登录信息保存到session种，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个方可固定访问一个后端服务器，可以解决session的问题。 核心代码如下12345upstream &#123; ip_hash; server localhost:8080; server localhost:8081;&#125; fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。12345upstream backend &#123; fair; server localhost:8080; server localhost:8081;&#125; url_hash（第三方）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method使使用的hash算法 核心代码如下123456upstream backend &#123; hash $request_uri; hash_method crc32; server localhost:8080; server localhost:8081;&#125; HTTP服务器Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现。 首先看看Nginx做静态资源服务器123456789server &#123; listen 80; server_name localhost; location / &#123; root e:\wwwroot; index index.html; &#125;&#125; 这样如果访问到 http://localhost 就会默认访问到E盘wwwroot目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署。 动静分离动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路。 核心代码如下123456789101112131415161718192021222324upstream test &#123; server localhost:8080; server localhost:8081;&#125;server &#123; listen 80; server_name localhost; location / &#123; root e:\wwwroot; index index.html; &#125; # 所有静态请求都由nginx处理 location ~ \.(gif|jpg|jpeg|png|bmp|swf|css|js)$ &#123; root e:\wwwroot; &#125; # 所有动态请求都转发给tomcat处理 location ~ \.(jsp|do)$ &#123; proxy_pass http://test; &#125;&#125; 这样我们就可以把html、图片、css以及js放到wwwroot目录下，而tomcat只复杂处理jsp和请求，例如当我们后缀为gif的时候，Nginx默认会从wwwroot获取到当前请求的动态图文件返回，当然这里的静态文件跟Nginx是同意爱服务器，我们也可以在另外一台服务器，然后通过反向代理和负载均衡配置过去就好了。 实际业务中用到的conf文件分析主要代码如下12345678910111213141516171819202122232425server &#123; listen 80; # host中绑定的www.kdzs.com实际是localhost server_name www.kdzs.com; # 静态资源从这里返回，缓存的过期时间是1天 location ~* ^.+\.(woff|woff2|ttf|json|log|jpg|jpeg|gif|png|ico|html|cfm|cfc|afp|asp|lasso|pl|py|txt|fla|swf|zip)$ &#123; root /Users/admin/Documents/kdzs; expires 1d; &#125; # jss、css和less这些静态资源依然走这个目录，过期时间2小时 location ~* ^.+\.(js|css|less)$ &#123; root /Users/admin/Documents/kdzs; expires 2h; &#125; # 监听80端口，当访问www.kdzs.com:80的时候 # 会将请求转发到 http://101.37.111.40 # 最后将结果返回给客户端 location ~ /&#123; proxy_pass http://101.37.111.40; &#125;&#125; 可以看到，项目中用到了反向代理和将Nginx作为静态资源服务器。PS：如果将www.kdzs.com的host绑定到测试环境，经过验证，不会走进本地Nginx配置。关于这个可以这么理解，Nginx在本地起了一个服务器，如果请求的是本地，则会走进此服务器，如果请求的是其他域名，则不会走进本地Nginx服务器，即和本地Nginx没有关系。 参考 https://www.geekjc.com/post/58e70c55e8d0c72d3c4fa340#4. http://blog.51cto.com/freeloda/1288553]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>网络</tag>
        <tag>服务器</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【基础篇】git高级操作]]></title>
    <url>%2F2018%2F08%2F27%2Fgit%E9%AB%98%E7%BA%A7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Rebase改命令可以说和merge命令得到的结果基本是一致的通常merge操作将分支上的代码合并到master中，分支样子如下所示 使用rebase后，会将develop上的commit按顺序移到master的第三个commit后面，分支样子如下 rebase对比merge优点： 合并后的结果很清晰，只有一条线 缺点： 如果一旦出现冲突，解决冲突很麻烦，可能要解决多个冲突，但是merge出现冲突只需要解决一次 使用rebase应该在需要被rebase的分支上操作，并且该分支是本地分支。12345## branch developgit rebase mastergit checkout master## 用于将 master 上的 HEAD 移动到最新的commitgit merge develop stashstash用于临时保存工作目录的改动。开发中可能会遇到代码写一半需要切分支打包的问题，如果这时候你不想commit的话，就可以使用该命令1git stash 使用该命令可以暂存你的工作目录，恢复如下1git stash pop reflogreflog可以看到HEAD的移动记录，加入之前误删了一个分支，可以通过git reflog看到移动HEAD的哈希值 从图中可以看出，HEAD的最后一次移动行为是merge后，接下来分支new就被删除了，那么我们可以通过以下命令找回new分支 12git checkout 37d9acagit checkout -b new reflog 记录是时效的，只会保存一段时间内的记录。 Reset如果你想删除刚写的commit，就可以通过以下命令实现 1git reset --hard HEAD^ 但是reset的本质并不是删除了commit，而是重新设置了HEAD和它指向的branch。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>Git高级操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【算法篇】树、动态规划及字符串相关]]></title>
    <url>%2F2018%2F08%2F27%2F%E6%A0%91%E5%92%8C%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[树非递归实现中先序、中序、后续遍历非递归实现使用了栈的结构，通过栈的先进后出模拟递归实现。 以下是先序遍历代码实现123456789101112131415161718192021function pre(root) &#123; if(root)&#123; let stack = []; // 先将根节点 push stack.push(root); // 判断栈中是否为空 while(stack.length &gt; 0)&#123; // 弹出栈顶元素 root = stack.pop(); console.log(root); // 因为先序遍历是先左后右，栈是先进后出结构 // 所以先push右边再push左边 if(root.right)&#123; stack.push(root.right); &#125; if(root.left)&#123; stack.push(root.left); &#125; &#125; &#125;&#125; 以下是中序遍历代码实现1234567891011121314151617181920function mid(root) &#123; if(root)&#123; let stack = []; // 中序遍历是先左再根最后右 // 所以首先应该先把最左边节点遍历到底依次push进栈 // 当左边没有节点时，就打印栈顶元素，然后寻找右节点 // 对于最左边的叶节点来说，可以把它看成是两个 null 节点的父节点 // 左边打印不出东西就把父节点拿出来打印，然后再看右节点 while(stack.length &gt; 0 || root)&#123; if(root) &#123; stack.push(root); root = root.left; &#125;else&#123; root = stack.pop(); console.log(root); root = root.right; &#125; &#125; &#125;&#125; 以下是后续遍历代码实现，该代码使用了两个栈来实现遍历，相比一个栈的遍历来说要容易理解得多123456789101112131415161718192021222324function pos(root) &#123; if(root)&#123; let stack1 = []; let stack2 = []; // 后续遍历是先左再右最后根 // 所以对于一个栈来说，应该先push根节点 // 然后push右节点，最后push左节点 stack1.push(root); while(stack1.length &gt; 0)&#123; root = stack1.pop(); stack2.push(root); if(root.left)&#123; stack1.push(root.left); &#125; if(root.right)&#123; stack1.push(root.right) &#125; &#125; while(stack2.length &gt; 0)&#123; console.log(stack2.pop()); &#125; &#125;&#125; 中序遍历的前驱后续节点实现这个算法的前提是节点有一个parent的指针指向父节点，根节点指向null 如果所示，该树的中序遍历结果是4,2,5,1,6,3,7 前驱节点对于节点2来说，他的前驱节点就是4，按照中序遍历规则（左、根、右），可以得出以下结论 如果选取的节点的左节点不为空，就找该左节点最右的节点。对于节点1来说，他有左节点2，那么节点2的最右节点就是5 如果左节点为空，且目标节点是父节点的右节点，那么前驱节点为父节点。对于节点5来说，没有左节点，且是节点2的右节点，所以节点2是前驱节点 如果左节点为空，且目标节点是父节点的左节点，向上寻找到第一个是父节点的右节点的节点。对于节点6来说，没有左节点，且是节点3的左节点，所以向上寻找到节点1，发现节点3是节点1的右节点，所以节点1是节点6的前驱节点 代码实现12345678910111213141516171819202122function predecessor(node)&#123; if(!node) rteurn; // 结论1 if(node.left)&#123; return getRight(node.left); &#125;else&#123; let parent = node.parent; // 结论23的判断 while(parent &amp;&amp; parent.right === node)&#123; node = parent; parent = node.parent; &#125; retrn parent; &#125;&#125;function getRight(node)&#123; if(!node) return; node = node.right; while(node) node = node.right; return node;&#125; 后继节点对于节点2来说，他的后继节点就是5，按照中序遍历原则，可以得出以下结论 如果有右节点，就找到该右节点的最左节点。对于节点1来说，他有右节点3，那么节点3的最左节点就是6 如果没有右节点，就向上遍历直到找到一个节点是父节点的左节点。对于节点5来说，没有右节点，就向上寻找到节点2，该节点是父节点1的左节点，所以节点1是后继节点 代码实现：1234567891011121314151617181920212223function successor(node)&#123; if(!node) return; // 结论1 if(node.right)&#123; return getLeft(node.right); &#125;else&#123; // 结论2 let parent = node.parent; // 判断parent为空 while(parent &amp;&amp; parent.left === node)&#123; node = parent; parent = node.parent; &#125; return parent; &#125;&#125;function getLeft(node)&#123; if(!node) return node = node.left; while(node) node = node.left; return node;&#125; 动态规划动态规划背后的基本思想非常简单，就是将一个问题拆分为子问题，一般来说这些子问题都是非常相似的，那么我们可以通过只解决一次每个子问题来达到减少计算量的目的。 一旦得出每个子问题的解，就存储该结果以便下次使用。 斐波那契数列斐波那契数列就是从0和1开始，后面的数都是前两个数之和。那么显而易见，我们可以通过递归的方式来完成求解斐波那契数列 12345function fib(n) &#123; if(n &lt; 2 &amp;&amp; n &gt;= 0) return n; return fib(n - 1) + fib(n - 2);&#125;fib(10); 以上代码已经可以完美的解决问题，但是以上解法却存在很严重的性能问题，当n越大的时候，需要的时间是指数增长的，这时候就可以通过动态规划来解决这个问题。 动态规划的本质其实就两点 自底向上分解子问题 通过变量存储已经计算过的解 根据上面两点，斐波那契数列的动态规划思路也就出来了 斐波那契数列从0和1开始，那么这就是这个子问题的最底层 通过数组来存储每一位所对应的斐波那契数列的值 12345678910function fib(n)&#123; let array = new Array(n + 1).fill(null); array[0] = 0; array[1] = 1; for(let i = 2; i &lt;= n; i++)&#123; array[i] = array[i - 1] + array[i - 2]; &#125; return array[n];&#125;fib(10); 0 - 1 背包问题该问题可以描述为：给定一组物品，没种物品都有自己的重量和价格，在限定的总重量内，我们如何选择，才能使得物品的总价格最高。每个问题只能放入至多一次。 假设我们有以下物品 物品ID/重量 价值 1 3 2 7 3 12 对于一个总容量为5的背包来说，我们可以放入重量2和3的物品来达到背包被的物品总价值最高。对于这个问题来说，子问题就两个，分别是放物品和不放物品，可以通过以下表格来理解子问题 物品ID/剩余容量 0 1 2 3 4 5 1 0 3 3 3 3 3 2 0 3 7 10 10 10 3 0 3 7 12 15 19 直接来分析能放三种物品的情况，也就是最后一行 当容量少于3时，只取上一行对应的数据，因为当前容量不能容纳物品3 当容量为3时，考虑两种情况，分别为放入物品3和不放物品3 不放物品3的情况下，总价值为10 放入物品3的情况下，总价值为12，所以应该放入物品3 当容量为4时，考虑两种情况，分别为放入物品3和不放物品3 不放物品3的情况下，总价值为10 放入物品3的情况下，和放入物品1的价值相加，得出总价值为15，所以应该放入物品3 当容量为5时，考虑两种情况，分别为放入物品3和不放物品3 不放物品3的情况下，总价值为10 放入物品3的情况下，和放入物品2的价值相加，得出总价值为19，所以应该放入物品3 代码如下1234567891011121314151617181920212223242526272829303132333435363738/** * @param &#123;*&#125; w 物品重量 * @param &#123;*&#125; v 物品价值 * @param &#123;*&#125; c 总容量 * @returns */function knapsack(w,v,c)&#123; let length = w.length; if(length === 0) return 0; // 对照表格，生成的二维数组，第一维代表物品，第二维代表背包剩余容量 // 第二维中的元素代表背包物品总价值 let array = new Array(length).fill(new Array(c + 1).fill(null)); // 完成底部子问题的解 for(let i = 0; i &lt;= c; i++)&#123; // 对照表格第一行，array[0]代表物品1 // i代表剩余总容量 // 当剩余总容量大于物品1的重量时，记录下背包物品总价值，否则价值为0 array[0][i] = i &gt;= w[0] ? v[0] : 0; &#125; // 自底向上开始解决子问题，从物品2开始 for(let i = 1; i &lt; length; i++)&#123; for(let j = 0; j &lt;= c; j++)&#123; // 这里求解子问题，分别为不放当前物品和放当前物品 // 先求不放当前物品的背包总价值，这里的值也就是对应表格中上一行对应的值 array[i][j] = array[i - 1][j]; // 判断当前剩余容量是否可以放入当前物品 if(j &gt;= w[i])&#123; // 可以放入的话，就比大小 // 放入当前物品和不放入当前物品，哪个背包总价值大 array[i][j] = Math.max(array[i][j], v[i] + array[i -1][j - w[i]]) &#125; &#125; &#125; return array[length - 1][c];&#125; 最长递增子序列这个问题的动态思路解法很简单，直接上代码12345678910111213141516function lis(n) &#123; if(n.length === 0) return 0; let array = new Array(n.length).fill(1); for(let i = 1; i &lt; n.length; i ++)&#123; for(let j = 0; j &lt; i; j++)&#123; if(n[i] &gt; n[j])&#123; array[i] = Math.max(array[i], 1 + array[j]); &#125; &#125; &#125; let res = 1; for(let i = 0; i &lt; array.length; i++)&#123; res = Math.max(res, array[i]); &#125; return res;&#125; 字符串相关在字符串相关的算法中，Trie树可以解决很多问题，同时又具备良好的空间和时间复杂度，比如以下问题 词频统计 前缀匹配]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>算法</tag>
        <tag>动态规划</tag>
        <tag>树</tag>
        <tag>字符串相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【浏览器篇】浏览器的缓存策略]]></title>
    <url>%2F2018%2F08%2F19%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E7%9A%84%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[通常浏览器缓存策略分为两种 强缓存实现强缓存可以通过两种响应头实现，表示在缓存期间不需要请求，state code为200 Expires：HTTP/1.0的产物，表示在XX时间后过期，受限于本地时间 Cache-Control：HTTP/1.1，优先级高于Expires，值为max-age=xx，表示xx秒后过期 协商缓存 Last-Modified和If-Modified-Since：Last-Modified表示本地文件最后修改日期，If-Modified-Since会将 Last-Modified的值发送给服务器，询问服务器在该日期后资源是否有更新，有更新的话就会将新的资源发送 回来。但是如果在本地打开缓存文件，就会造成Last-Modified被修改，所以在HTTP/1.1中出现了ETag。 ETag和If-None-Match：Etag类似于文件指纹，If-None-Match会将当前Etag发送给服务器，询问该资源ETag 是否有变动，有的话则将新的资源发送回来。优先级比Last-Modified高。 对于大部分的场景都可以使用强缓存配合协商缓存解决，但是在一些特殊的地方可能需要选择特殊的缓存策略 对于某些不需要缓存的资源，可以使用Cache-Control: no-store 对于频繁变动的资源，可以使用Cache-Control配合ETag使用 对于代码文件来说，可以使用Cache-Control: max-age=3153600，并配合缓存策略使用，然后对文件进行指纹吹，一旦文件名变动就会下载新的文件]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>浏览器</tag>
        <tag>缓存策略</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【算法篇】排序与链表]]></title>
    <url>%2F2018%2F08%2F18%2F%E6%8E%92%E5%BA%8F%E5%92%8C%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[排序排序算法是计算机中比较常用的算法，这边整理了如下几种排序算法： 冒泡排序 插入排序 选择排序 归并排序 快排 堆排序 以下两个函数是排序中会用到的通用函数 123456789function checkArray(array)&#123; if(!array || array.length &lt;= 2) return false; return true;&#125;function swap(array, left, right)&#123; let rightValue = array[right]; array[right] = array[left]; array[left] = rightValue;&#125; 冒泡排序冒泡排序的原理如下，从第一个元素开始，把当前元素和下一个索引元素进行比较。如果当前元素大，那么就交换位置，重复操作直到比较到最后一个元素，那么此时最后一个元素就是该数组中最大的数。下一轮重复以上操作，但是此时最后一个元素已经是最大数了，所以不需要再比较最后一个元素，只需要比较到 length - 1 的位置。 1234567891011121314function bubble(arr) &#123; let continue = checkArray(arr); if(!continue) &#123; return; &#125; for(let i = arr.length - 1; i &gt; 0; i--)&#123; // 从0到length - 1遍历 for(let j = 0; j &lt; i; j++)&#123; if(arr[j] &gt; arr[j + 1])&#123; swap(arr, j, j+1); &#125; &#125; &#125;&#125; 该算法的操作次数是一个等差数列 n + (n - 1) + (n - 2) + …… + 1 ，去掉常数项以后得出时间复杂度是O(n * n) 插入排序插入排序的原理如下。第一个元素默认是已排序元素，取出下一个元素和当前元素比较，如果当前元素大就交换位置。那么此时第一个元素就是当前的最小数，所以下次取出操作从第三个元素开始，向前对比，重复之前的操作。 123456789101112function insertion(arr) &#123; let continue = checkArray(arr); if(!continue) &#123; return; &#125; for(let i = 1; i &lt; arr.length; i++)&#123; for(let j = i - 1; j &gt;=0 &amp;&amp; arr[j] &gt; arr[j + 1]; j--)&#123; swap(arr, j, j + 1); &#125; &#125; return arr;&#125; 该算法的操作次数是一个等差数列 n + (n - 1) + (n - 2) + …… + 1 ，去掉常数项以后得出时间复杂度是O(n * n) 选择排序选择排序的原理如下。遍历数组，设置最小值的索引为0，如果取出的值比当前最小值小，就替换最小值索引，遍历完成后，将第一个元素和最小值索引上的值交换。如上操作后，第一个元素就是数组中的最小值，下次遍历就可以从索引1开始重复上述操作。 1234567891011121314function selection(arr) &#123; let continue = checkArray(arr); if(!continue) &#123; return; &#125; for(let i = 0; i &lt; arr.length; i++)&#123; let minIndex = i; for(let j = i + 1; j &lt; arr.length; j++)&#123; minIndex = arr[j] &lt; arr[minIndex] ? j : minIndex; &#125; swap(arr, i, minIndex); &#125; retrn arr;&#125; 时间复杂度O(n * n)。 归并排序递归的将数组两两分开直到最多包含两个元素，然后将数组排序合并，最终合并为排序好的数组。假设我有一组数组[3,1,2,8,9,7,6]，中间数索引是3，先排序数组[3,1,2,8]。在这个左边数组上，继续拆分直到变成数组包含两个元素（如果数组长度是奇数的话，会有一个拆分数组只包含一个元素）。然后排序数组[3,1]和[2,8]，然后再排序数组 [1,3,2,8]，这样左边数组就排序完成，然后按照以上思路排序右边数组，最后将数组[1,2,3,8]和[6,7,9]排序。 12345678910111213141516171819202122232425262728293031323334353637function sort(arr) &#123; let continue = checkArray(arr); if(!continue) &#123; return; &#125; mergeSort(arr, 0, arr.length - 1); return arr;&#125;function mergeSort(arr, left, right) &#123; // 左右索引相同说明已经只有一个数 if(left === right) return; // 等同于 left + (right - left) / 2 // 相比 (left + right) / 2 更加安全，不会溢出 // 使用位运算，因为快 let mid = parseInt(left + (right - left) &gt;&gt; 1); mergeSort(arr, left, mid); mergeSort(arr, mid + 1, right); let help = []; let i = 0; let p1 = left; let p2 = mid + 1; while(p1 &lt;= mid &amp;&amp; p2 &lt;= right)&#123; help[i++] = arr[p1] &lt; arr[p2] ? arr[p1++] : arr[p2++]; &#125; while(p1 &lt;= mid)&#123; help[i++] = arr[p1++]; &#125; while(p2 &lt;= right) &#123; help[i++] = arr[p2++]; &#125; for(let i = 0; i &lt; help.length; i++)&#123; arr[left + i] = help[i]; &#125; return arr;&#125; 时间复杂度O(N * logN)。 快排随机选取一个数组中的值作为基准值，从左至右取值与基准值对比大小。比基准值小的放数组左边，大的放右边，对比完成后将基准值和第一个比基准值大的值交换位置。然后将数组以基准值的位置分为两部分，继续递归以上操作。 12345678910111213141516171819202122232425262728293031323334function sort(arr)&#123; let continue = checkArray(arr); if(!continue) &#123; return; &#125; quickSort(arr, 0, arr.length - 1); return arr;&#125;function quickSort(arr, left, right)&#123; if(left &lt; right)&#123; swap(arr, , right); let indexs = part(arr, parseInt(Math.random() * (right - left + 1)) + left, right); quickSort(arr, left, indexs[0]); quickSort(arr, indexs[1] + 1, right); &#125;&#125;function part(arr, left, right)&#123; let less = left - 1; let more = right; while(left &lt; more) &#123; if(arr[left] &lt; arr[right])&#123; ++less; ++left; &#125;else if(arr[left] &gt; arr[right])&#123; swap(arr, --more, left); &#125;else &#123; left ++; &#125; &#125; swap(arr, right, more); return [less, more];&#125; 该算法的复杂度和归并排序是相同的，但是额外空间复杂度比归并排序少，只需O(logN)，并且相比归并排序来说，所需的常数时间也更少。 堆排序堆排序利用了二叉堆的特性来做，二叉堆通常用数组表示，并且二叉堆是一颗完全二叉树（所有叶子节点都是从左往右顺序排序，并且其他层的节点都是满的）。二叉堆又分为大根堆与小根堆。 大根堆是某个节点的所有子节点的值都比他小 小根堆是某个节点的所有子节点的值都比他大 堆排序的原理就是组成一个大根堆或者小根堆。以小根堆为例，某个节点的左边子节点索引是 i 2 + 1，右边是i 2 + 2 ，父节点是 (i - 1) / 2。 首先遍历数组，判断该节点的父节点是否比他小，如果小就交换位置并继续判断，直到他的父节点比他大。 重新以上操作1，直到数组首位是最大值 将首位和末尾交换位置并将数组长度减一，表示数组末尾已是最大值，不需要再比较大小。 对比左右节点哪个大，然后记住大的节点的索引并且和父节点对比大小，如果子节点大就交换位置 重复 3-4 直到整个数组都是大根堆 1234567891011121314151617181920212223242526272829303132333435363738394041function heap(arr) &#123; let continue = checkArray(arr); if(!continue) &#123; return; &#125; // 将最大值交换到首位 for(let i = 0; i &lt; arr.length; i++)&#123; heapInsert(arr, i); &#125; let size = arr.length; // 交换首位和末尾 swap(arr, 0, --size); while(size &gt; 0)&#123; heapify(arr, 0, size); swap(arr, 0, --size); &#125; return arr;&#125;function heapInsert(arr, index)&#123; // 如果当前节点比父节点大，就交换 while(arr[index] &gt; arr[parseInt((index - 1) / 2)])&#123; swap(arr, index, parseInt((index - 1) / 2)); // 将索引变成父节点 index = parseInt((index - 1) / 2); &#125;&#125;function heapify(arr, index, size) &#123; let left = index * 2 + 1; while(left &lt; size) &#123; // 判断左右节点大小 let largest = left + 1 &lt; size &amp;&amp; arr[left] &lt; arr[left + 1] ? left + 1 : left; // 判断子节点和父节点大小 largest = arr[index] &gt; arr[largest] ? largest : index; if(largest === index) break; swap(arr, index, largest); index = largest; left = index * 2 + 1; &#125;&#125; 以上实现了小根堆，如果需要实现大根堆，只需要把节点对比反一下就好。该算法复杂度是O(logN)。 系统自带排序实现每个语言的排序内部实现都是不同的。对于js来说，数组长度大于10会采用快排，否则使用插入排序。选择插入排序是因为虽然时间复杂度很差，但是在数据量很小的情况下和O(n * logN) 相差无几，然后插入排序需要的时间常数很小，所以相对别的排序来说更快。 对于java来说，还会考虑内部的元素的类型。对于存储对象的数组来说，会采用稳定性好的算法。稳定性的意思就是对于相同值来说，相对顺序不能改变。 链表反转单向链表思路很简单，使用三个变量分别表示当前节点和当前节点的前后节点。12345678910111213141516171819function reverseList(head)&#123; // 判断下变量边界问题 if(!head || !head.next) return head; // 初始设置为空，因为第一个节点反转后就是尾部，尾部节点指向 null let pre = null; let current = head; let next; // 判断当前节点是否为空 // 不为空就先获取当前节点的下一节点 // 然后把当前节点的next设为上一个节点 // 然后把current设为下一个节点，pre设为当前节点 while(current) &#123; next = current.next; current.next = pre; pre = current; current = next; &#125; return pre;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>算法</tag>
        <tag>排序</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【算法篇】时间复杂度与位运算]]></title>
    <url>%2F2018%2F08%2F18%2F%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E4%B8%8E%E4%BD%8D%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[时间复杂度通常使用最差的时间复杂度来衡量一个算法的好坏。 常数时间O(1)代表这个操作和数据量没关系，是一个固定时间的操作，比如说四则运算。 对于一个算法来说，可能会计算出如下操作次数 aN + 1，N 代表数据量。那么该算法的时间复杂度就是O(N)。因为我们在计算时间复杂度的时候，数据量通常是非常大的，这时候低阶项和常数项可以忽略不计。 当然可能会出现两个算法都是O(N)的时间复杂度，那么对比两个算法的好坏就要通过对比低阶项和常数项了。 位运算位运算在算法中很有用，速度可以比四则运算快很多。 在学习位运算之前应该知道十进制如何转二进制，二进制如何转十进制。这里说明下简单的计算方式： 十进制 33 可以看成是 32 + 1 ，并且 33 应该是六位二进制的，因为 33 近似 32，而 32 是2的五次方，所以是六位，那么十进制 33 就是 100001 ，只要是2的此房，那么就是1，否则都为0 二进制 100001 同理，首位是2^5，末位是2^0，相加得出 33 左移 &lt;&lt;110 &lt;&lt; 1 // -&gt; 20 左移就是将二进制全部往左移动，10在二进制中表示为1010，左移一位后变为10100，转变为10进制也就是20，所以基本可以把左移堪称是 a * (2 ^ b) 右移 &gt;&gt;110 &gt;&gt; 1 // -&gt; 5 右移就是将二进制全部往右移动并去除多余的右边，所以右移等于 a / (2 ^ b) 右移很好用，比如可以用在二分算法取中间值 按位操作按位与 &amp;每一位都为1，结果才为1128 &amp; 7// 1000 &amp; 0111 -&gt; 0000 -&gt; 0 按位或 |其中一位为1，结果就是1128 | 7// 1000 | 0111 -&gt; 1111 -&gt; 15 按位异或 ^每一位都不同，结果才为1123458 ^ 7// 1000 ^ 0111 -&gt; 1111 -&gt; 158 ^ 8// 1000 ^ 1000 -&gt; 0000 -&gt; 0 从以上代码中可以发现按位异或就是不进位加法 两个数不使用四则运算得出和这道题中可以按位异或，因为按位异或就是不进位加法， 8 ^ 8 = 0，如果进位了，就是16了，所以我们只需要将两个数进行异或操作，然后进位。那么也就是说两个二进制都是1的位置，左边应该有一个进位1，所以可以得出以下公式 a + b = (a ^ b) + ((a &amp; b) &lt;&lt; 1) ，然后通过迭代的方式模拟加法。 1234567function sum(a, b)&#123; if(a == 0) return b if(b == 0) return a let newA = a ^ b; let newB = (a &amp; b) &lt;&lt; 1; return sum(newA, newB);&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>算法</tag>
        <tag>时间复杂度</tag>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从iframe高度自适应了解postMessage]]></title>
    <url>%2F2018%2F08%2F12%2FpostMessage%2F</url>
    <content type="text"><![CDATA[背景： iframe在我们的项目里用的比较多，也是为了复用一些代码，在这样的情况下，iframe的高度自然而然就成了一个大问题，不合适的iframe高度会使页面出现2个及以上的滚动条，这对用户体验及美观（前端的强迫症）来说都是比较痛苦的。因此我们需要让iframe的高度达到一个合适的高度，从而达到除了外部的滚动条外，不产生多余的其他滚动条。 如何用postMessage来实现？ postMessage的实现类似sub、pub，首先需要在父页面绑定一个接收事件，接收来自子页面的message事件，一般会用origin来判断是否来自期望的子页面。 父页面接收消息父页面伪代码如下： 123456789101112131415161718192021222324window.addEventListener(&apos;message&apos;, function(e)&#123; /* * e里面会有一些参数，我们用到以下两个 * e.origin 来源 * e.data 参数 */ //判断origin是否来自xxx，是则将data传递过去 if(e.origin == &apos;xxx&apos;)&#123; callback(e.data); &#125;&#125;);function callback(data) &#123; //判断事件名，执行相应的操作 if(data.eventName == &apos;changeHeight&apos;)&#123; changeHeight(data.height); &#125;&#125;function changeHeight(height) &#123; var selector = &apos;xxx&apos;; selector.height = height;&#125; 子页面发送消息 otherWindow.postMessage(data, targetOrigin, [transfer]); otherWindow 其他窗口的一个引用，比如iframe的contentWindow属性、执行window.open返回的窗口对象、或者是命名过或数值索引的window.frames。 data 将要发送到其他 window的数据。它将会被结构化克隆算法序列化。这意味着你可以不受什么限制的将数据对象安全的传送给目标窗口而无需自己序列化。 targetOrigin 通过窗口的origin属性来指定哪些窗口能接收到消息事件，其值可以是字符串”“（表示无限制）或者一个URI。在发送消息的时候，如果目标窗口的协议、主机地址或端口这三者的任意一项不匹配targetOrigin提供的值，那么消息就不会被发送；只有三者完全匹配，消息才会被发送。这个机制用来控制消息可以发送到哪些窗口；例如，当用postMessage传送密码时，这个参数就显得尤为重要，必须保证它的值与这条包含密码的信息的预期接受者的orign属性完全一致，来防止密码被恶意的第三方截获。如果你明确的知道消息应该发送到哪个窗口，那么请始终提供一个有确切值的targetOrigin，而不是。不提供确切的目标将导致数据泄露到任何对数据感兴趣的恶意站点。 transfer 是一串和message 同时传递的 Transferable 对象. 这些对象的所有权将被转移给消息的接收方，而发送一方将不再保有所有权。 子页面伪代码如下： 1234567var data = &#123; eventName: &apos;changeHeight&apos;, height: $(&apos;body&apos;).height()&#125;;var targetOrigin = &apos;https://p1.kuaidizs.com&apos;;window.postMessage(data, targetOrigin); 以上，我们就完成了使用postMessage来改变父页面的高度。 注意事项 使用message来接收消息时，为了安全起见，请对origin进行判断，防止不期望的页面发起攻击 使用message来发送事件时，请明确targetOrigin，防止第三方截获你发送的数据]]></content>
      <categories>
        <category>个人原创</category>
      </categories>
      <tags>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>postMessage</tag>
        <tag>massageChannel</tag>
        <tag>个人原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【基础篇】数据结构]]></title>
    <url>%2F2018%2F08%2F11%2FdataMap%2F</url>
    <content type="text"><![CDATA[数据结构栈概念栈是一个线性结构，在计算机中是一个相当常见的数据结构。栈的特点是只能在某一段添加或删除数据，遵循先进后出的原则。 实现可以把栈看成是数组的一个子集，所以可以使用数组来实现。1234567891011121314151617181920Class Stack&#123; constructor() &#123; this.stack = []; &#125; push(item) &#123; this.stack.push(item); &#125; pop() &#123; this.stack.pop(); &#125; peek() &#123; return this.stack[this.getCount() - 1] &#125; getCount() &#123; return this.stack.length &#125; isEmpty() &#123; return this.getCount() === 0; &#125;&#125; 应用参考leetcode 序号20的题目，匹配有效括号 队列概念队列是一个线性结构，特点是在某一端添加数据，在另一端删除数据，遵循先进先出的原则。 实现单链队列单链队列在出队操作的时候需要 O(n) 的时间复杂度1234567891011121314151617181920class Queue&#123; constructor() &#123; this.queue = []; &#125; enQueue(item) &#123; this.queue.push(item); &#125; deQueue() &#123; return this.queue.shift(); &#125; getHeaer() &#123; return this.queue[0]; &#125; getLength() &#123; return this.queue.length; &#125; isEmpty() &#123; return this.getLength() === 0; &#125;&#125; 循环队列出队操作平时的时间复杂度为O(1)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465class SqQueue &#123; constructor(length) &#123; this.queue = new Array(length + 1); //队头 this.first = 0; //队尾 this.last = 0; //当前队列大小 this.size = 0; &#125; enQueue(item) &#123; // 判断队尾 + 1是否为队头 // 如果是就代表需要扩容数组 // % this.queue.length 是为了防止数组越界 if(this.first === (this.last + 1) % this.queue.length) &#123; this.resize(this.getLength() * 2 + 1); &#125; this.queue[this.last] = item; this.size ++; this.last = (this.last + 1) % this.queue.length; &#125; deQueue() &#123; if(this.isEmpty()) &#123; throw Error('Queue is empty'); &#125; let r = this.queue[this.first]; this.queue[this.first] = null; this.first = (this.first + 1) % this.queue.length; this.size --; // 判断当前队列大小是否过小 // 为了保证不浪费空间，在队列空间等于总长度四分之一时 // 且不为2时缩小总长度为当前的一半 if(this.size === this.getLength() / 4 &amp;&amp; this.getLength() !== 2)&#123; this.resize(this.getLength() / 2); &#125; return r; &#125; getHeader() &#123; if(this.isEmpty())&#123; throw Error('queue is empty'); &#125; return this.queue[this.first]; &#125; getLength() &#123; return this.queue.length - 1; &#125; isEmpty() &#123; return this.first === this.last; &#125; resize(length) &#123; let q = new Array(length); for(let i = 0; i &lt; length; i++)&#123; q[i] = this.queue[(i + this.first) % this.queue.length] &#125; this.queue = q; this.first = 0; this.last = this.size; &#125;&#125; 链表概念链表是一个线性结构，同时也是一个天然的递归结构。链表结构可以充分利用计算机内存空间，实现灵活的内存动态管理。但是链表失去了数组随机读取的优点，同时链表由于增加了节点的指针域，空间开销比较大。 单向链表实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980class Node &#123; constructor(v, next) &#123; this.value = v; this.next = next; &#125;&#125;class LinkList &#123; constructor() &#123; // 链表长度 this.size = 0; // 虚拟头部 this.dummyNode = new Node(null, null); &#125; find(header, index, currentIndex) &#123; if(index === currentIndex) return header; return this.find(header.next, index, currentIndex + 1); &#125; addNode(v, index) &#123; this.checkIndex(index); // 当往链表末尾插入时，prev.next为空 // 其他情况时，因为要插入节点，所以插入的节点 // 的next 应该是 prev.next let prev = this.find(this.dummyNode, index, 0); prev.next = new Node(v, prev.next); this.size ++; return prev.next; &#125; insertNode(v, index) &#123; return this.addNode(v, index); &#125; addToFirst(v) &#123; return this.addNode(v, 0); &#125; addToLast(v) &#123; return this.addNode(v, this.size); &#125; removeNode(index, isLast) &#123; this.checkIndex(index); index = isLast ? index - 1 : index; let prev = this.find(this.dummyNode, index, 0); let node = prev.next; prev.next = node.next; node.next = null; this.size --; return node; &#125; removeFirstNode() &#123; return this.removeNode(0); &#125; removeLastNode() &#123; return this.removeNode(this.size, true); &#125; checkIndex(index) &#123; if(index &lt; 0 || index &gt; this.size) throw Error('Index Error'); &#125; getNode(index) &#123; this.checkIndex(index); if(this.isEmpty()) return return this.find(this.dummyNode, index, 0).next; &#125; isEmpty() &#123; return this.size === 0; &#125; getSize() &#123; return this.size; &#125;&#125; 树二叉树树拥有很多种结构，二叉树是树中最常用的结构，同时也是一个天然的递归结构。二叉树拥有一个根节点，每个节点至多拥有两个子节点，分别为：左节点和右节点。树的最底部节点称之为叶节点，当一棵树的叶数量为满时，该树可以称之为满二叉树 二分搜索树二分搜索树也是二叉树，拥有二叉树的特性。但是区别在于二分搜索树每个节点的值都比它的左子树的值大，比右子树的值小。 这种存储方式很适合于数据搜索。如下图，当需要查找6的时候，因为需要查找的值比根节点的值大，所以只需要在根节点的右子树上寻找，大大提高了搜索效率。 实现 12345678910111213141516171819202122232425262728293031323334353637383940class Node &#123; constructor(value) &#123; this.value = value; this.left = null; this.right = null; &#125;&#125;class BST &#123; constructor() &#123; this.root = null; this.size = 0; &#125; getSize() &#123; return this.size; &#125; isEmpty() &#123; return this.size === 0; &#125; addNode(v) &#123; this.root = this._addChild(this.root, v); &#125; // 添加节点时，需要比较添加的节点值和当前节点值的大小 _addChild(node, v) &#123; if(!node) &#123; this.size ++; return new Node(v); &#125; if(node.value &gt; v) &#123; node.left = this._addChild(node.left, v); &#125;else if(node.value &lt; v)&#123; node.right = this._addChild(node.right, v); &#125; &#125;&#125; 以上是最基本的二分搜索树实现，接下来实现树的遍历。 对于树的遍历来说，有三种遍历方法，分别是 先序遍历 中序遍历 后序遍历 三种遍历的区别在于何时访问节点。在遍历树的过程中，每个节点都会遍历三次，分别是 遍历到自己 遍历左子树 遍历右子树 如果需要实现先序遍历，只需要第一次遍历到节点时进行操作即可。 递归实现1234567891011121314151617181920212223242526272829303132333435363738394041// 先序遍历可用于打印树的结构// 先序遍历先访问根节点，然后访问左节点，最后访问右节点。preTraversal() &#123; this._pre(this.root);&#125;_pre(node) &#123; if(node) &#123; console.log(node.value); this._pre(node.left); this._pre(node.right); &#125;&#125;// 中序遍历可用于排序// 对于BST来说，中序遍历可以实现一次遍历就得到有序的值// 中序遍历表示先访问左节点，然后访问根节点，最后访问右节点。midTraversal() &#123; this._mid(this.root);&#125;_mid(node) &#123; if(node)&#123; this._mid(node.left); console.log(node.value); this._mid(node.right); &#125;&#125;// 后序遍历可用于先操作子节点再操作父节点的场景// 后序遍历表示先访问左节点，然后访问右节点，最后访问根节点。backTraversal() &#123; this._back(this.root);&#125;_back(node) &#123; if(node) &#123; this._back(node.left); this._back(node.right); console.log(node.value); &#125;&#125; 以上的这几种遍历都可以称之为深度遍历，对应的还有种遍历叫做广度遍历，也就是一层层地遍历树。对于广度遍历来说，我们需要利用之前讲过的队列结构来完成。 123456789101112131415breadthTraversal() &#123; if(!this.root) return null; let q = new Queue(); // 将根节点入队 q.enQueue(this.root); // 循环判断队列是否为空，为空代表树遍历完毕 while(!q.isEmpty()) &#123; // 将队首出队，判断是否有左右子树 // 有的话，就先左后右入队 let n = q.deQueue(); console.log(n.value); if(n.left) q.enQueue(n.left); if(n.right) q.enQueue(n.right); &#125;&#125; 如何在树中寻找最小值或最大值呢？因为二分搜索树的特性，所以最小值一定在根节点的最左边，最大值相反1234567891011121314getMin() &#123; return this._getMin(this.root).value;&#125;_getMin(node) &#123; if(!node.left) return node; return this._getMin(node.left);&#125;getMax() &#123; return this._getMax(this.root).value;&#125;_getMax(node) &#123; if(!node.right) return node; return this._getMax(node.right);&#125; 向上取整和向下取整，这两个操作是相反的，所以代码也是类似的，这里只介绍如何向下取整。既然是向下取整，那么根据二分搜索树的特性，值一定在根节点的左侧。只需要一直遍历左子树直到当前节点的值不再大于等于需要的值，然后判断节点是否还拥有右子树，如果有的话，继续递归判断 12345678910111213141516floor(v) &#123; let node = this._floor(this.root, v); return node ? node.value : null;&#125;_floor(node, v) &#123; if(!node) return null; if(node.value === v) return v; // 如果当前节点值还比需要的值大，就继续递归 if(node.value &gt; v) &#123; return this._floor(node.left, v); &#125; // 判断当前节点是否拥有右子树 let right = this._floor(node.right, v); if(right) return right; return node;&#125; 排名，这是用于获取给定值的排名或者排名第几的节点的值，这两个操作也是相反的，所以这个只介绍如何获取排名第几的节点的值。对于这个操作而言，我们需要略微的改造点代码，让每个节点拥有一个size属性，该属性表示该节点下有多少子节点（包括自身） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Node &#123; constructor(value) &#123; this.value = value; this.left = null; this.right = null; // 修改代码 this.size = 1; &#125;&#125;//新增代码_getSize(node) &#123; return node ? node.size : 0;&#125;_addChild(node, v) &#123; if(!node)&#123; return new Node(v); &#125; if(node.value &gt; v) &#123; // 修改代码 node.size ++; node.left = this._addChild(node.left, v); &#125; else if(node.value &lt; v) &#123; // 修改代码 node.size ++; // FIXME node.right = this._addChild(node.right, v); &#125; return node;&#125;select(k) &#123; let node = this._select(this.root, k); return node ? node.value : null;&#125;_select(node, k) &#123; if(!node) return null; // 先获取左子树下有几个节点 let size = node.left ? node.left.size : 0; // 判断size是否大于k // 如果大于k，代表所需要的节点在左节点 if(size &gt; k) return this._select(node.left, k); // 如果小于k，代表所需要的节点在右节点 // 注意这里需要重新计算 k，减去根节点除了右子树的节点数量 if(size &lt; k) return this._select(node.right, k-size-1); return node;&#125; 接下来我们看二分搜索树中最难实现的部分：删除节点。因为对于删除节点来说，会存在以下几种情况 需要删除的节点没有子树 需要删除的节点只有一条子树 需要删除的节点有左右两条树 对于前两种情况很好解决，但是第三种情况就有难度了，所以先来实现相对简单的操作：删除最小节点，对于删除最小节点来说，是不存在第三种情况的，删除最大节点操作是和删除最小节点相反的，所以这里也就不再赘述。 1234567891011121314delectMin() &#123; this.root = this._delectMin(this.root); console.log(this.root);&#125;_delectMin(node) &#123; // 一直递归左子树 // 如果左子树为空，就判断节点是否拥有右子树 // 有右子树的话就把需要删除的节点替换为右子树 if((node != null) &amp; !node.left) return node.right; node.left = this._delectMin(node.left); // 最后需要重新维护下节点的 size node.size = this._getSize(node.left) + this._getSize(node.right) + 1; return node;&#125; 最后讲解的就是如何删除任意节点了。对于这个操作，T.Hibbard在1962年提出了解决这个难题的办法，也就是如何解决第三种情况。 当遇到这种情况时，需要取出当前节点的后继节点（也就是当前节点右子树的最小节点）来替换需要删除的节点。然后将需要删除节点的左子树赋值给后继节点，右子树删除后继节点后赋值给它。 因为二分搜索树的特性，父节点一定比所有左子节点大，比所有右子节点小。那么当需要删除父节点时，势必需要拿出一个比父节点大的节点来替换父节点。这个节点肯定不存在于左子树，必然存在于右子树。然后又需要保持父节点都是比右子节点小的，那么就可以取出右子树中最小的那个节点来替换父节点。 1234567891011121314151617181920212223242526272829303132delect(v) &#123; this.root = this._delect(this.root, v);&#125;_delect(node, v) &#123; if(!node) return null; // 寻找节点比当前节点小，去左子树找 if(node.value &lt; v)&#123; node.right = this._delect(node.right, v); &#125;else if(node.value &gt; v)&#123; // 寻找的节点比当前节点大，去右子树找 node.left = this._delect(node.left, v); &#125; else &#123; // 进入这个条件说明已经找到节点 // 先判断节点是否拥有左右子树中的一个 // 是的话，将子树返回出去，这里和 _delectMin 的操作一样 if(!node.left) return node.right; if(!node.right) return node.left; // 进入这里，代表节点拥有左右子树 // 先取出当前节点的后继节点，也就是取当前节点右子树的最小值 let min = this._getMin(node.right); // 取出最小值后，删除最小值 // 然后把删除节点后的子树赋值给最小值节点 min.right = this._delectMin(node.right); // 左子树不动 min.left = node.left; node = min; &#125; //维护size node.size = this._getSize(node.left) + this._getSize(node.right) + 1; return node;&#125; AVL树概念二分搜索树实际在业务中是受到限制的，因为并不是严格的O(logN)，在极端情况下会退化成链表，比如加入一组升序的数字就会造成这种情况。 AVL树改进了二分搜索树，在AVL树中任意节点的左右子树的高度差都不大于1，这样保证了时间复杂度是严格的O(logN)。基于此，对AVL树增加或删除节点时可能需要旋转树来达到高度的平衡。 实现因为AVL树是改进了二分搜索树，所以部分代码是于二分搜索树重复的，对于重复内容不再解析。对于AVL树来说，添加节点会有四种情况。 对于左左情况来说，新增加的节点位于节点2的左侧，这时树已经不平衡了，需要旋转。因为搜索树的特性，节点比左节点大，比右节点小，所以旋转以后也要实现这个特性。 旋转之前：new &lt; 2 &lt; C &lt; 3 &lt; B &lt; 5 &lt; A，右旋之后节点3为根节点，这时候需要将节点3的右节点加到节点5的左边，最后还需要更新节点的高度。 对于右右情况，相反与左左，不再赘述。 对于左右情况来说，新增加的节点位于节点4的右侧。对于这种情况，需要通过两次旋转来达到目的。 首先对节点的左节点左旋，这时树满足左左的情况，再对节点进行一次右旋就可以达到目的。 代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990class Node &#123; constructor(value) &#123; this.value = value; this.left = null; this.right = null; this.height = 1; &#125;&#125;class AVL &#123; constructor() &#123; this.root = null; &#125; addNode(v) &#123; this.root = this._addChild(this.root, v); &#125; _addChild(node, v) &#123; if(!node) &#123; return new Node(v); &#125; if(node.value &gt; v) &#123; node.left = this._addChild(node.left, v); &#125; else if(node.value &lt; v) &#123; node.right = this._addChild(node.right, v); &#125; else &#123; node.value = v; &#125; node.height = 1 + Math.max(this._getHeight(node.left), this._getHeight(node.right)); let factor = this._getBalanceFactor(node); // 当需要右旋时，根节点的左树一定比右树高度高 if(factor &gt; 1 &amp;&amp; this._getBalanceFactor(node.left) &gt;= 0)&#123; return this._rightRotate(node); &#125; // 当需要左旋时，根节点的左树一定比右树高度矮 if(factor &lt; -1 &amp;&amp; this._getBalanceFactor(node.right) &lt;= 0)&#123; return this._leftRotate(node); &#125; // 左右情况 // 节点的左树比右树高，且节点的左树的右数比节点的左树的左数高 if(factor &gt; 1 &amp;&amp; this._getBanlanceFactor(node.left) &lt; 0) &#123; node.left = this._leftRotate(node.left); return this._rightRotate(node); &#125; // 右左情况 // 节点的左树比右树矮，且节点的右树的右数比节点的右树的左数矮 if(factor &lt; -1 &amp;&amp; this._getBalanceFactor(node.right) &gt; 0)&#123; node.right = this._rightRotate(node.right); return this._leftRotate(node); &#125; return node; &#125; _getHeight(node) &#123; if(!node) return 0; return node.height; &#125; _getBalanceFactor(node) &#123; return this._getHeight(node.left) - this._getHeight(node.right); &#125; // 节点右旋 _rightRotate(node) &#123; // 旋转后新根节点 let newRoot = node.left; // 需要移动的节点 let moveNode = newRoot.right; // 节点2的右节点改为节点5 newRoot.right = node; // 节点5的左节点改为节点3 node.left = moveNode; // 更新树的高度 node.height = 1 + Math.max(this._getHeight(node.left), this._getHeight(node.right)); newRoot.height = 1 + Math.max(this._getHeight(newRoot.left), this._getHeight(newRoot.right)); return newRoot; &#125; // 节点左旋 _leftRotate(node) &#123; // 旋转后新根节点 let newRoot = node.right; // 需要移动的节点 let moveNode = newRoot.left; // 节点6的左节点改为节点4 newRoot.left = node; // 节点4的右节点改为节点5 node.right = moveNode; // 更新树的高度 node.height = 1 + Math.max(this._getHeight(node.left), this._getHeight(node.right)); newRoot.height = 1 + Math.max(this._getHeight(newRoot.left), this._getHeight(newRoot.right)); return newRoot; &#125;&#125; Trie概念在计算机科学，trie又称前缀树或字典树，是一种有序树，用于保存关联数组，其中的键通常是字符串。 简单点来说，这个结构的作用大多是为了方便搜索字符串，该树有以下几个特点 根节点代表空字符串，每个节点都有N（加入搜索英文字符，就有26条）条连接，每条链接代表一个字符 节点不存储字符，只有路径才存储，这点和其他的树结构不同 从根节点开始到任意一个节点，将沿途经过的字符连接起来就是该节点对应的字符串。 实现总得来说Trie的实现相比别的树结构来说简单的多，实现就以搜索英文字符为例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263class TrieNode &#123; constructor() &#123; // 代表每个字符经过节点的次数 this.path = 0; // 代表到该节点的字符串有几个 this.end = 0; // 链接 this.next = new Array(26).fill(null); &#125;&#125;class Trie &#123; constructor() &#123; // 根节点，代表空字符 this.root = new TrieNode(); &#125; // 插入字符串 insert(str) &#123; if(!str) return; let node = this.root; for(let i = 0; i &lt; str.length; i++) &#123; // 获得字符先对应的索引 let index = str[i].charCodeAt() - 'a'.charCodeAt(); // 如果索引对应没有值，就创建 if(!node.next[index]) &#123; node.next[index] = new TrieNode(); &#125; node.path += 1; node = node.next[index]; &#125; node.end += 1; &#125; // 搜索字符串出现的次数 search(str) &#123; if(!str) return; let node = this.root; for(let i = 0; i &lt; str.length; i++)&#123; let index = str[i].charCodeAt() - 'a'.charCodeAt(); // 如果索引对应没有值，代表没有需要搜索的字符串 if(!node.next[index]) &#123; return 0; &#125; node = node.next[index]; &#125; return node.end; &#125; // 删除字符串 delete(str) &#123; if(!this.search(str)) return; let node = this.root; for(let i = 0; i &lt; str.length; i++)&#123; let index = str[i].charCodeAt() - 'a'.charCodeAt(); // 如果索引对应的节点的Path为0，代表经过该节点的字符串 // 已经一个，直接删除即可 if(--node.next[index].path == 0)&#123; node.next[index] = null; return; &#125; node = node.next[index]; &#125; node.end -= 1; &#125;&#125; 并查集概念并查集是一种特殊的树结构，用于处理一些不交集的合并及查询问题。该结构中每个节点都有一个父节点，如果只有当前一个节点，那么该节点的父节点指向自己。 这个结构中有两个重要的操作，分别是 Find：确定元素属于哪一个子集。它可以被用来确定两个元素是否属于同一子集。 Union：将两个子集合并成同一个集合。 实现12345678910111213141516171819202122232425262728293031323334353637383940414243class DisjointSet &#123; constructor(count) &#123; // 初始化时，每个节点的父节点都是自己 this.parent = new Array(count); // 用于记录树的深度，优化搜索复杂度 this.rank = new Array(count); for(let i = 0; i &lt; count; i++)&#123; this.parent[i] = i; this.rank[i] = 1; &#125; &#125; find(p) &#123; // 寻找当前节点的父节点是否为自己，不是的话表示还没找到 // 开始进行路径压缩优化 // 假设当前节点父节点为A // 将当前节点挂载到A节点的父节点上，达到压缩深度的目的 while(p != this.parent[p]) &#123; this.parent[p] = this.parent[this.parent[p]]; p = this.parent[p]; &#125; return p; &#125; isConnected(p, q) &#123; return this.find(p) === this.find(q); &#125; // 合并 union(p, q) &#123; // 找到两个数字的父节点 let i = this.find(p); let j = this.find(q); if(i === j) return; // 判断两棵树的深度，深度小的加到深度大的树下面 // 如果两棵树深度相等，那就无所谓怎么加 if(this.rank[i] &lt; this.rank[j]) &#123; this.parent[i] = j; &#125; else if (this.rank[i] &gt; this.rank[j]) &#123; this.parent[j] = i; &#125; else &#123; this.parent[i] = j; this.rank[j] ++; &#125; &#125;&#125; 堆概念堆通常是一个可以被看做一棵树的数组对象。堆的实现通过构造二叉堆，实为二叉树的一种。这种数据结构具有以下性质。 任意节点小于（或大于）它的所有子节点 堆总是一棵完全树。即除了最底层，其他层的节点都被元素填满，且最底层从左到右填入。 将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。优先队列也完全可以用堆来实现，操作是一模一样的。 实现大根堆堆的每个节点的左边子节点索引是 i * 2 + 1 ，右边是 i * 2 + 2 ，父节点是 (i - 1) / 2 。堆有两个核心的操作，分别是 shiftUp 和 shiftDown 。前者用于添加元素，后者用于删除根节点。 shiftUp 的核心思路是一路将节点与父节点对比大小，如果比父节点大，就和父节点交换位置。 shiftDown 的核心思路是先将根节点和末尾交换位置，然后移除末尾元素。接下来循环判断父节点和两个子节点的大小，如果子节点大，就把最大的子节点和父节点交换。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class MaxHeap &#123; constructor() &#123; this.heap = []; &#125; size() &#123; reurn this.heap.length; &#125; empty() &#123; return this.size() == 0; &#125; add(item) &#123; this.heap.push(item); this._shiftUp(this.size() - 1); &#125; removeMax() &#123; this._shiftDown(0); &#125; getParentIndex(k) &#123; return parseInt((k - 1) / 2); &#125; getLeftIndex(k) &#123; return k * 2 + 1; &#125; _shiftUp(k) &#123; //如果当前节点比父节点大，就交换 while(this.heap[k] &gt; this.heap[this.getParentIndex(k)]) &#123; this._swap(k, this.getParentIndex(k)) //将索引变成父节点 k = this.getParentIndex(k); &#125; &#125; _shiftDown(k) &#123; //交换首位并删除末尾 this._swap(k, this.size() - 1); this.heap.splice(this.size() - 1, 1); // 判断节点是否有左孩子，因为二叉堆的特性，有右必有左 while(this.getLeftIndex(k) &lt; this.size())&#123; left j = this.getLeftIndex(k); // 判断是否有右孩子，并且右孩子是否大于左孩子 if(j + 1 &lt; this.size() &amp;&amp; this.heap[j + 1] &gt; this.heap[j]) j++ // 判断父节点是否已经比子节点都大 if(this.heap[k] &gt;= this.heap[j] ) break this._swap(k, j); k = j; &#125; &#125; _swap(left, right) &#123; let rightValue = this.heap[right]; this.heap[right] = this.heap[left]; this.heap[left] = rightValue; &#125;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【网络篇】Http、Https、Http 2.0 及 DNS]]></title>
    <url>%2F2018%2F08%2F07%2FHTTP%2F</url>
    <content type="text"><![CDATA[HTTPHTTP协议是个无状态协议，不会保存状态。 POST和GET的区别先引入副作用和幂等的概念。副作用指对服务器上的资源做改变，搜索是无副作用的，注册是副作用的。 幂等指发送M和N次请求（两者不同且都大于1），服务器上资源的状态一致，比如注册10个和11个账号是不幂等的，对文章进行更改10次和11次是幂等的。 在规范的应用场景上说，GET多用于无副作用、幂等的场景，例如搜索关键字。POST多用于副作用、不幂等的场景，例如注册。 在技术上说： GET请求能缓存，POST不能 POST相对GET安全一点点，因为GET请求都包含在URL里，且会被浏览器保存历史记录，POST不会，但是在抓包的情况下都是一样的。 POST可以通过request body来传输比GET更多的数据，GET没有这个技术 URL有长度限制，会影响GET请求，但是这个长度限制是浏览器规定的，不是RFC规定的 POST支持更多编码类型且不对数据类型限制 常见状态码2XX 成功 200 OK，表示从客户端发来的请求在服务器端被正确处理 204 No content，表示请求成功，但响应报文不含实体的主体部分 205 Reset Content，表示请求成功，但响应报文不含实体的主体部分，但是与204不同自傲与要求请求方重置内容 206 Partial Content，进行范围请求 3XX 重定向 301 moved permanently，永久性重定向，表示资源已被分配了新的URL 302 found，临时性重定向，表示资源临时被分配了新的URL 303 see other，表示资源存在着另一个URL，应使用GET方法定向获取资源 304 not modified，表示服务器允许访问资源，但因发生请求未满足条件的情况 307 temporary redirect，临时重定向，同302 4XX 客户端错误 400 bad request，请求报文存在语法错误 401 unauthorized，表示发送的请求需要有通过HTTP认证的认证信息 403 forbidden，表示对请求资源的访问被服务器拒绝 404 not found，表示在服务器上没有找到请求的资源 5XX 服务器错误 500 internal server error，表示服务器端在执行请求时发生了错误 501 Not Implemented，表示服务器不支持当前请求所需要的某个功能 503 service unavailable，表示服务器暂时处于超负载或正在停机维护，无法处理请求 HTTP首部 通用字段 作用 Cache-Control 控制缓存的行为 Connection 浏览器想要优先使用的链接类型，比如keep-alive Date 创建报文时间 Pragma 报文指令 Via 代理服务器相关信息 Transfer-Encoding 传输编码方式 Upgrade 要求客户端升级协议 Warning 在内容中可能存在错误 请求字段 作用 Accept 能正确接收的媒体类型 Accept-Charset 能正确接收的字符集 Accept-Encoding 能正确接收的编码格式列表 Accept-Language 能正确接收的语言列表 Expect 期待服务端的指定行为 From 请求方邮箱地址 Host 服务器的域名 if-Match 两端资源标记比较 if-Modified-Since 本地资源未修改返回304（比较时间） if-None-Match 本地资源未修改返回304（比较标记） User-Agent 客户端信息 Max-Forwards 限制可被代理及王网关转发的次数 Proxy-Authorization 向代理服务器发送验证信息 Range 请求某个内容的一部分 Referer 表示浏览器所访问的前一个页面 TE 传输编码方式 响应字段 作用 Accept-Ranges 是否支持某些种类的范围 Age 资源在代理缓存中存在的时间 ETag 资源标识 Location 客户端重定向到某个URL Proxy-Authenticate 向代理服务器发送验证信息 Server 服务器名字 WWW-Authenticate 获取资源需要的验证信息 实体字段 作用 Allow 资源的正确请求方式 Content-Encoding 内容的编码格式 Content-Language 内容使用的语言 Content-Length request body 长度 Content-Location 返回数据的备用地址 Content-MD5 Base64加密格式的内容 MD5校验值 Content-Range 内容的位置范围 Content-Type 内容的媒体类型 Expires 内容的过期时间 Last_modified 内容的最后修改时间 HTTPSHTTPS还是通过了HTTP来传输信息，但是信息通过TLS协议进行了加密。 TLSTLS协议位于传输层智商，应用层之下。首次进行TLS协议传输需要两个RTT，接下来可以通过Session Resumption 减少到一个RTT。 在TLS中使用了两种加密技术，分别为：对称加密和非对称加密。 对称加密对称加密就是两边拥有相同的秘钥，两边都知道如何将密文加密解密。 非对称加密有公钥私钥之分，公钥所有人都可以知道，可以将数据用公钥加密，但是将数据解密必须使用私钥解密，私钥只有分发公钥的一方才知道。 TSL握手过程如下： 客户端发送一个随机值，需要的协议和加密方式 服务端收到客户端的随机值，自己也产生一个随机值，并根据客户端需求的协议和加密方式来使用对应的方式，发送自己的证书（如果需要验证客户端证书需要说明） 客户端收到服务端的证书并验证是否有效，验证通过会再生成一个随机值，通过服务端证书的公钥去加密这个随机值并发送给服务端，如果服务端需要验证客户端证书的话会附带证书 服务端收到加密过的随机值并使用私钥解密获得第三个随机值，这时候两端都拥有了三个随机值，可以通过这三个随机值按照之前约定的加密方式生成密钥，接下来的通信就可以通过该密钥来加密解密。 通过以上步骤可知，在TLS握手阶段，两端使用非对称加密的方式来通信，但是因为非对称加密损耗的性能比对称加密大，所以在正式传输数据时，两端使用对称加密的方式通信。 以上说明的都是TLS 1.2协议的握手情况，在1.3协议中，首次建立连接只需要一个RTT，后面恢复连接不需要RTT了。 HTTP 2.0HTTP 2.0相比于HTTP 1.X，可以说是大幅度提高了web的性能。 在HTTP 1.X中，为了性能考虑，我们会引入雪碧图、将小图内联、使用多个域名等等的方式。这一切都是因为浏览器限制了同一个域名下的请求数量，当页面中需要请求很多资源的时候，队头阻塞（Head of line blocking）会导致在达到最大请求数量时，剩余的资源需要等待其他资源请求完成后才能发起请求。 在HTTP 1.X中，因为队头阻塞的原因，你会发现请求是这样的 在HTTP 2.0中，因为引入了多路复用，你会发现请求是这样的 二进制传输HTTP 2.0中所有加强性能的核心点在于此。在之前的HTTP版本中，我们是通过文本的方式传输数据。在HTTP 2.0中引入了新的编码机制，所有传输的数据都会被分割，并采用二进制格式编码。 多路复用在 HTTP 2.0 中，有两个非常重要的概念，分别是帧(frame)和流(stream)。帧代表着最小的数据单位，每个帧会表示出该帧属于哪个流，流也就是多个帧组成的数据流。 多路复用，就是在一个TCP连接中可以存在多条流。换句话说，也就是可以发送多个请求，对端可以通过帧中的标识知道属于哪个请求。通过这个技术，可以避免 HTTP 旧版本中的队头阻塞问题，极大的提高传输性能。 Header压缩在 HTTP 1.X 中，我们使用文本的形式传输header，在header携带cookie的情况下，可能每次都需要重复传输几百到几千的字节。 在 HTTP 2.0 中，使用了HPACK压缩格式对传输的header进行编码，减少了header的大小。并在两端维护了索引表，用于记录出现过的header，后面再传输过程中就可以传输已经记录过的header的键名，对端收到数据后就可以通过键名找到对应的值。 服务端Push在 HTTP 2.0 中，服务端可以在客户端某个请求后，主动推送其他资源。 可以想象以下情况：某些资源客户端是一定会请求的，这时就可以采取服务端push的技术，提前给客户端推送必要的资源，这样就可以相对减少一点延迟时间。当然在浏览器兼容的情况下你也可以使用prefetch。 QUIC这是一个谷歌出品的基于UDP实现的同为传输层的协议，目标很远大，希望替代TCP协议。 该协议支持多路复用，虽然 HTTP 2.0 也支持多路复用，但是下层仍是TCP，因为TCP的重传机制，只要一个包丢失就得判断丢失包并且重传，导致发生队头阻塞的问题，但是UDP没有这个机制。 实现了自己的加密协议，通过类似TCP的TFO机制可以实现O-RTT，当然TLS 1.3已经实现了O-RTT了 支持重传和纠错机制（向前恢复），在只丢失一个包的情况下不需要重传，使用纠错机制恢复丢失的包 纠错机制：通过异或的方式，算出发出去的数据的异或值并单独发出一个包，服务端在发现有一个包丢失的情况下，通过其他数据包和异或值包算出丢失包 在丢失两个包或以上的情况就使用重传机制，因为算不出来了。 DNSDNS的作用就是通过域名查询到具体的IP。 因为IP存在数字和英文的组合（IPv6），很不利于人类记忆，所以就出现了域名。你可以把域名看成是某个IP的别名，DNS就是去查询这个别名的真正名称是什么。 在TCP握手之前就已经进行了DNS查询，这个查询是操作系统自己做的。当你在浏览器中想访问www.leeing.site时，会进行以下操作： 操作系统会首先在本地缓存中查询 没有的话会去系统配置的DNS服务器中查询 如果这时候还没得话，会直接去DNS根服务器查询，这一步查询会找出负责site这个一级域名的服务器 然后去该服务器查询leeing这个二级域名 接下来三级域名的查询其实是我们配置的，你可以给www这个域名配置一个IP，然后还可以给别的三级域名配置一个IP 以上介绍的是DNS迭代查询，还有种是递归查询，区别就是前者是由客户端去做请求，后者是由系统配置的DNS服务器做请求，得到结果后将数据返回给客户端。 PS：DNS是基于UDP做的查询 从输入URL到页面加载完成的过程？ 首先做DNS查询，如果这一步做了只能DNS解析的话，会提供访问速度最快的IP地址回来 接下来是TCP握手，应用层会下发数据给传输层，这里TCP协议会指明两端的端口号，然后下发给网络层。网络层中的IP协议会确定IP地址，并且指示了数据传输中如何跳转路由器。然后包会再被封装到数据链路层的数据帧结构中，最后就是物理层面的传输了 TCP握手结束后会进行TLS握手，然后就开始正式的传输数据 数据在进入服务端之前，可能还会先经过负载均衡的服务器，它的作用就是将请求合理的分发到多台服务器上，这时假设服务端会响应一个HTML文件 首先浏览器会判断状态码是什么，如果是200那就继续解析，如果是400或500的话就会报错，如果300的话会进行重定向，这里会有个重定向计数器，避免过多次的重定向，超过次数也会报错。 浏览器开始解析文件，如果是gzip格式的话会先解压一下，然后通过文件的编码格式知道该如何去解码文件。 文件解码成功后会正式开始渲染流程，先会根据HTML构建DOM树，有CSS的话会去构建CSSOM树。如果遇到script标签的话，会判断是否存在 async 或者 defer ，前者会并行进行下载并执行JS，后者会先下载文件，然后等待HTML解析完成后顺序执行，如果以上都没有，就会阻塞住渲染刘恒直到JS执行完毕。遇到文件下载的会去下载文件，这里如果使用HTTP 2.0协议的话会极大的提高多图的下载效率。 初始的HTML被完全加载和解析后会触发DOMContentLoaded事件 CSSOM树和DOM树构建完成后会开始生成Render树，这一步就是确定页面元素的布局、样式等等诸多方面的东西 在生成Render树的过程中，浏览器就开始调用GPU绘制，合成图层，将内容显示在屏幕上了。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>网络</tag>
        <tag>HTTP</tag>
        <tag>HTTPS</tag>
        <tag>HTTP 2.0</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【浏览器篇】浏览器中的Event Loop]]></title>
    <url>%2F2018%2F08%2F07%2FeventLoop%2F</url>
    <content type="text"><![CDATA[在讲Event loop之前，我们先思考一个问题 js为什么是单线程？原因可能是如果js是多线程，在多个线程中处理DOM就可能会发生问题（一个线程添加新节点，另一个线程中删除节点），当然可以引入读写锁解决这个问题 好了，接下来我们开始讲Event loop 简单的说，就是js在执行的过程中会产生执行环境，这些执行环境会被顺序的加入到执行栈中。如果遇到异步的代码，会被挂起并加入到Task（有多种Task）队列中。一旦执行栈为空，Event Loop就会从Task队列中拿出需要执行的代码并放入执行栈中执行，所以本质上来说，js中的异步行为还是同步的。 我们看下以下代码，以下代码输出’1’, ‘3’, ‘2’12345678console.log('1');setTimeout(()=&gt;&#123; console.log('2');&#125;, 0);console.log('3');//'1'//'3'//'2' 之前对setTimeout理解有偏差，虽然设置了为0，其实还是异步，是因为html5标准规定这个函数的第二个参数不得小于4ms，不足会自动增加。 Task队列分为两种 微任务microtask，es6中称为jobs。以下这些行为属于微任务 process.nextTick promise Object.observe MutationObserver 宏任务macrotask，es6中称为task。以下这些行为属于宏任务 script setTimeout setInterval setImmediate I/O UI rendering 误区：很多人认为微任务快于宏任务，其实是错误的。因为宏任务汇中包括了script，浏览器会先执行一个宏任务，接下来有异步代码的话就先执行微任务。 正确的一次Event loop顺序应该是这样的： 执行同步代码（这属于宏任务） 执行栈为空，查询是否有微任务需要执行 执行所有微任务 必要的话渲染UI 开始下一轮Event loop，执行宏任务中的异步代码 通过上述的Event loop顺序可知，如果宏任务中的异步代码有大量的计算并且需要操作DOM的话，为了更快的界面响应，我们可以把操作DOM放入微任务中。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>浏览器</tag>
        <tag>Event loop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【React篇】分析diff算法]]></title>
    <url>%2F2018%2F08%2F07%2FReactDiff%2F</url>
    <content type="text"><![CDATA[diff算法大家都耳熟能详，React中最值得称道的部分莫过于Virtual DOM与diff的完美结合，特别是其高效的diff算法，可以让用户无需顾忌性能问题而“任性自由”地刷新页面。因为diff会帮助我们计算出Virtual DOM中真正变化的部分，并只针对该部分进行原生DOM操作，而非重新渲染整个页面，从而保证了每次操作更新后页面的高效渲染。 传统的diff算法diff算法，即微分算法。计算一颗树形结构转换成另一颗树形结构的最少操作，是一个复杂且值得研究的问题。传统diff算法通过循环递归对节点进行依次对比，效率低下，算法复杂度达到O(n^3)，其中n是树中节点的总数。这意味着如果要展示1000个节点，就要依次执行上十亿次的比较。这种指数型的性能消耗对于前端渲染场景来说太可怕了！ react中的diff算法diff策略首先，我们需要知道react的diff算法有3个策略 WebUI中DOM节点跨层级的移动操作特别少，可以忽略不计 拥有相同类的两个组件将会生成相似的树形结构，拥有不同类的两个组件将会生成不同的属性结构 对于同一层级的一组子节点，它们可以通过唯一id进行区分 tree diff基于策略一，React对树的算法进行了简洁明了的优化，即对树进行分层比较，两棵树只会对同一层级进行比较。当发现节点不存在时，测该节点及其子节点会全部被删掉，不会进行进一步的比较。 如果出现了节点跨层级的移动，diff会有怎样的表现呢？ 假设有A、B两个父节点，a、b两个子节点，形如A-&gt;a,B-&gt;b，当a从A之下移动到A、B平级时，当A发现a不在了，则会删除a及a的子节点，当A、B这一层级发现多出了a时，则会创建一个a。 这是一种影响react性能的操作，因此官方建议不要进行dom节点跨层级的操作。component diffreact是基于组件构建应用的，对于组件间的比较所采取的策略也是非常简洁、高效的。 如果是同一类型的组件，按照原策略继续比较Virtual Dom树即可 如果不是，则将该组件判断为dirty component，从而替换整个组件下的所有子节点。 对于同一类型的组件，有可能其Virtual Dom没有任何变化，如果能够确切的知道这点，那么就可以节省大量的diff运算时间。因此react提供shouldComponentUpdate()来判断该组件是否需要进行diff算法分析。 这里存在一个问题，如果有一个组件D，下面有E、F两个子节点，当D变为G时，虽然子节点依然是E、F，但react会认为它是不同类型的组件，会直接删除D，重新创建G，尽管D和G结构相似。这时虽然diff会影响性能，但正如diff策略二所言：不同类型的组件很少存在相似dom树的情况，因此这种极端因素很难在实际开发过程中造成重大的影响。 element diff当节点处于同一层级时，diff提供了3种节点操作。 增 INSERT_MARKUP 删 REMOVE_NODE 移 MOVE_EXISTING 增和删比较好理解，这里不再赘述了，这里主要讲一下“移”。按照diff策略三，我们在同一层级的节点上加入了唯一id，以下简称key。 当没有添加key时，移是比较蛋疼的，假设有一组旧节点A、B、C、D和一组新节点B、A、D、C，此时diff发现 B!=A，则创建并插入B至新集合，删除旧集合A，以此类推，创建并插入A、D、C，删除B、C、D。这怎么玩？ 当有了key之后，那就愉快多了。依然是上述的两组新旧节点，此时diff通过key发现新旧集合中的节点都是相同的节点，因此无需进行节点删除和创建，只需要将旧集合中节点的位置进行移动即可。 那么具体是怎么移动的呢？依然是上述的A、B、C、D和B、A、D、C。首先对新集合中的节点进行遍历，通过key判断新旧集合中是否存在相同的节点，如果存在，则移动。但在移动之前需要将当前节点在旧集合中的位置oldIndex与lastIndex进行比较，如果lastIndex &gt; oldIndex，则进行移动。 以A为例，在新集合中，发现A的lastIndex = 1，旧集合中oldIndex = 0，此时lastIndex &gt; oldIndex，则将A进行移动，并将lastIndex更新为新集合中A的位置。A.oldIndex此时为1。进入下一个节点的判断…… react中diff的不足与待优化的点？如果A、B、C、D更新为D、A、B、C，理论上只要移动D即可，然而由于D在就集合中的位置是最大的，导致实际是A、B、C移动到D之后。因此建议在开发过程中，尽量减少类似将最后一个节点移动到列表首部的操作，当节点数量过大或更新操作过于频繁时，这在一定程度上会影响react的渲染性能。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>React</tag>
        <tag>diff算法</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【网络篇】UDP 和 TCP]]></title>
    <url>%2F2018%2F08%2F07%2FUDP%2F</url>
    <content type="text"><![CDATA[UDP面向报文UDP是一个面向报文（报文可以理解为一段段的数据）的协议。意思就是UDP只是报文的搬运工，不会对报文进行任何拆分和拼接操作。 具体来说 在发送端，应用层将数据传递给传输层的UDP协议，UDP只会给数据增加一个UDP头标识下是UDP协议，然后就传递给网络层了 在接收端，网络层将数据传递给传输层，UDP只去除IP报文头就传递给应用层，不会任何拼接操作 不可靠性 UDP是无连接的，也就是说通信不需要建立和断开。 UDP是不可靠的，协议收到什么数据就传递什么数据，并且也不会备份数据，对方能不能收到也不关心。 UDP没有拥塞控制，一直会以恒定的速度发送数据。即使网络条件不好，也不会对发送速率进行调整。 弊端：在网络条件不好的情况下会导致丢包 优点：在某些实时性要求高的场景（比如电话会议），就需要使用UDP而不是TCP 高效因为UDP没有TCP那么复杂，需要保证数据不丢失且有序到达，所以UDP的头部开销小，只有八字节，相比TCP的至少二十字节要少得多，在传输数据报文时是很高效的。 头部包含了以下数据 两个十六位的端口号，分别为源端口（可选字段）和目标端口 整个数据报文的长度 整个数据报文的校验和（IPv4可选字段），该字段用于发现头部信息和数据中的错误 传输方式UDP不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说UDP提供了单播、多播、广播的功能。 TCP头部TCP头部比UDP复杂的多，对于TCP头部来说，以下几个字段是很重要的 Sequence number，这个序号保证了TCP传输的报文都是有序的，对端可以通过序号的顺序拼接报文。 Acknowledgement Number，这个序号表示数据接收端期望接收的下一个字节的编号是多少，同时也表示上一个序号的数据已经收到 Window Size，窗口大小，表示还能接收多少字节的数据，用于流量控制 标识符 URG=1：该字段为一表示本数据报的数据部分包含紧急信息，是一个高优先级数据报文，此时紧急指针有效。紧急数据一定位于当前数据包数据部分的最前面，紧急指针表明了紧急数据的尾部。 ACK=1：该字段为一表示确认号字段有效。此外，TCP还规定在连接建立后传送的所有报文段都必须把ACK置为一。 PSH=1：该字段为一表示接收端应该立即将数据push给应用层，而不是等到缓冲区满后再提交。 RST=1：该字段为一表示当前TCP连接出现严重问题，可能需要重新建立TCP连接，也可以用于拒绝非法的报文段和拒绝连接请求。 SYN=1：当SYN=1，ACK=0时，表示当前报文段是一个连接请求报文。当SYN=1，ACK=1时，表示当前报文段是一个同意建立连接的应答报文。 FIN=1：该字段为一表示此报文段是一个释放连接的请求报文。 状态机HTTP是无连接的，所以作为下层的TCP协议也是无连接的，虽然看似TCP将两端连接了起来，但是其实只是两端共同维护了一个状态。 TCP的状态机是很复杂的，并且与建立断开连接时的握手息息相关，接下来就来详细描述下两种握手。在这之前需要了解一个重要的性能指标RTT，该指标表示发送端发送数据到接收到对端数据所需的往返时间。 建立连接的三次握手在TCP协议中，主动发起请求的一端为客户端，被动连接的一端称为服务端。不管是客户端还是服务端，TCP连接建立完成后都能发送和接收数据，所以TCP也是一个全双工的协议。 起初，两端都为CLOSED状态。在通信开始前，双方都会创建TCB。服务器创建完TCB后变进入LISTEN状态，此时开始等待客户端发送数据。 第一次握手（请求连接）客户端向服务端发送连接请求报文段。该报文段中包含自身的数据通讯初始序号。请求发送后，客户端便进入SYN-SENT状态，x表示客户端的数据通信初始序号。 第二次握手（同意连接）服务端收到连接请求报文段后，如果同意连接，则会发送一个应答，该应答中也会包含自身的数据通讯出书序号，发送完成后便进入SYN-RECEIVED状态。 第三次握手（确认应答）当客户端收到连接同意的应答后，还要向服务端发送一个确认报文。客户端发完这个报文段后便进入ESTABLISHED状态，服务端收到这个应答后也进入ESTABLISHED状态，此时连接建立成功。 第三次握手可以包含数据，通过TCP快速打开（TFO）技术。其实只要涉及到握手的协议，都可以使用类似TFO的方式，客户端和服务端存储相同cookie，下次握手时发出cookie达到减少RTT的目的。 明明两次握手就可以建立起链接，为什么还需要第三次应答这是为了防止失效的连接请求报文段被服务端接收，从而产生错误。 可以想象如下场景：客户端发送了一个连接请求A，但是因为网络原因造成了超时，这时TCP会启动超时重传的机制，再次发送一个连接请求B。此时请求顺利到达服务端，服务端应答完就建立了请求。如果连接请求A在两端关闭后终于抵达了服务端，那么这时服务端会认为客户端又需要建立TCP连接，从而应答了该请求并进入ESTABLISHED状态。此时客户端其实是CLOSED状态，那么就会导致服务端一直等待，造成资源的浪费。 在建立连接中，任意一端掉线，TCP都会重发SYN包，一般会重试五次，在建立连接中可能会遇到SYN FLOOD攻击。遇到这种情况你可以选择调低重试次数或者干脆在不能处理的情况下拒绝请求。 断开连接的四次握手TCP是全双工的，在断开连接时两端都需要发送FIN和ACK。 第一次握手（请求释放）若客户端A认为数据发送完成，则它需要向服务端B发送连接释放请求。 第二次握手（同意释放）B收到连接释放请求后，会告诉应用层要释放TCP连接。然后会发送ACK包，并进入CLOSE_WAIT状态，表示A到B的连接已经释放，不接收A发的数据了。但是因为TCP连接是双向的，所以B仍旧可以发送数据给A。 第三次握手（继续发没发完的请求）B如果此时还有没发完的数据会继续发送，完毕后会向A发送连接释放请求，然后B遍进入LAST-ACK状态 通过延迟确认的技术（通常有时间限制，否则对方会误认为需要重传），可以将第二次和第三次握手合并，延迟ACK包的发送。 第四次握手（确认应答）A收到释放请求后，向B发送确认应答，此时A进入TIME-WAIT状态。该状态会持续2MSL（最大段生存期，指报文段在网络中生存的时间，超时会被抛弃）时间，若该时间段内没有B的重发请求的话，就进入CLOSED状态。当B收到确认应答后，也便进入CLOSED状态。 为什么A要进入TIME-WAIT状态，等待2MSL时间后才进入CLOSED状态？为了保证B能收到A的确认应答。若A发完确认应答后直接进入CLOSED状态，如果确认应答因为网络问题一直没有到达，那么会造成B不能正常关闭。 ARQ协议ARQ协议也就是超时重传机制。通过确认和超时机制保证了数据的正确发送。包含以下两部分 停止等待ARQ 连续ARQ 停止等待ARQ 正常传输过程 只要A向B发送一段报文，都要停止发送并启动一个定时器，等待对端回应，在定时器时间内接收到对端应答就取消定时器并发送下一段报文。 报文丢失或出错 在报文传输的过程中可能会出现丢包。这时候超时定时器设定的时间就会再次发送丢包的数据直到对端响应，所以需要每次都备份发送的数据。 即使报文正常的传输到对端，也可能出现在传输过程中报文出错的问题。这时候对端会抛弃该报文并等待A端重传。 一般定时器设定的时间都会大于一个RTT的平均时间。 ACK超时或丢失 对端传输的应答也可能出现丢失或超时的情况。那么超过定时器时间A端照样会重传报文。这时候B端收到相同序号的报文会丢弃该报文并重传应答，直到A端发送下一个序号的报文。 在超时的情况下也可康出现应答很迟到达，这时A端会判断该序号是否已经接收过，如果接收过只需要丢弃应答即可。 这个协议的缺点就是传输效率低，在良好的网络环境下每次发送报文都得等待对端的ACK。 连续ARQ在连续ARQ中，发送端拥有一个发送窗口，可以在没有收到应答的情况下持续发送窗口内的数据，这样相比停止等待ARQ协议来说减少了等待时间，提高了效率。 累计确认 连续ARQ中，接收端会持续不断收到报文。如果和停止等待ARQ中接收一个报文就发送一个应答一样，就太浪费资源了。通过累积确认，可以在收到多个报文后统一回复一个应答报文。报文中的ACK可以用来告诉发送端这个序号之前的数据已经全部接受到了，下次请发送这个序号+1的数据。 但是累计确认也有一个弊端。在连续接收报文时，可能会遇到接收到序号5的报文后，并未接到序号6的报文，然而序号7以后的报文已经接收。遇到这种情况时，ACK只能回复6，这样会造成发送端重复发送数据，这种情况下可以通过Sack来解决，这个会在下文说到。 滑动窗口上面讲到了发送窗口。在TCP中，两端都维护着窗口 发送端窗口 接收端窗口 发送端窗口包含已发送但未收到应答的数据和可以发送但是未发送的数据。发送端窗口是由接收端窗口剩余大小决定的。接收方会把当前接收窗口的剩余大小写入应答报文，发送端收到应答后根据该值和当前网络拥塞情况设置发送端窗口大小，所以发送端窗口大小是不断变化的。 当发送端接收到应答报文后，会随之将窗口进行滑动 滑动窗口实现了流量控制。接收方通过报文告知发送方还可以发送多少数据，从而保证接收方能够来得及接收数据。 Zero窗口在发送报文的过程中，可能会遇到对端出现零窗口的情况。在该情况下，发送端会停止发送数据，并启动persistent timer。该定时器会定时发送请求给对端，让对端告知窗口大小。在重试次数超过一定次数后，可能会中断TCP连接。 拥塞处理拥塞处理和流量控制不同，后者是作用于接收方，保证接收方来得及接受数据。而前者是作用于网络，防止过多的数据拥塞网络，避免出现网络负载过大的情况。 拥塞处理包括了四个算法，分别为 慢开始 拥塞避免 快速重传 快速恢复 慢开始算法顾名思义，就是在传输开始时将发送窗口慢慢指数级扩大，从而避免一开始就传输大量数据导致网络拥塞。具体步骤如下 连接初始设置拥塞窗口（Congestion Window）为1MSS（一个分段的最大数据量） 每过一个RTT就将窗口大小乘二 指数级增长肯定不能没有限制的，所以有一个阈值限制，当窗口大小大于阈值时就会启动拥塞避免算法。 拥塞避免算法此算法相对简单点，每过一个RTT窗口大小只加一，这样能够避免指数级增长导致网络拥塞，慢慢将大小调整到最佳值。 在传输过程中可能出现定时器超时的情况，这时候TCP会认为网络拥塞了，会马上进行以下步骤： 将阈值设为当前拥塞窗口的一半 将拥塞窗口设为1MSS 启动拥塞避免算法 快速重传快速重传一般和快速恢复一起出现。一旦接收端收到的报文出现失序的情况，接收端只会回复最后一个顺序正确的报文序号（没有Sack的情况下）。如果收到三个重复的ACK，无需等待定时器超时再重发而是启动快速重传。具体算法分为两种： TCP Taho 将阈值设为当前拥塞窗口的一半 将拥塞窗口设为1MSS 重新开始慢开始算法 TCP Reno 拥塞窗口减半 将阈值设为当前拥塞窗口 进入快恢复阶段（重发对端需要的包，一旦收到一个新的ACK答复就退出该阶段） 使用拥塞避免算法 TCP New Reno 改进后的快速恢复TCP New Reno 算法改进了之前 TCP Reno 算法的缺陷。在之前，快恢复中只要收到一个新的ACK包，就会退出快恢复。 在 TCP New Reno 中，TCP发送方先记下三个重复ACK的分段的最大序号。 假如我有一个分段数据是1~10这十个序号的报文，其中丢失了序号为3和7的报文，那么该分段的最大序号就是10。发送端只会收到ACK序号为3的应答。这时候重发序号为3的报文，接收方顺利接收并会发送ACK序号为7的应答。这时候TCP知道对端是有多个包未收到，会继续发送序号为7的报文，接收方顺利接收并会发送ACK序号为11的应答，这时发送端认为这个分段接收端已经顺利接收，接下来会退出快速恢复阶段。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>基础知识</tag>
        <tag>计算机通识</tag>
        <tag>网络</tag>
        <tag>TCP</tag>
        <tag>UDP</tag>
      </tags>
  </entry>
</search>
